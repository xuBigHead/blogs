---
layout: post
title: Redis 数据过期淘汰.md
categories: [Redis]
description: 
keywords: Redis 数据过期淘汰.md
mermaid: false
sequence: false
flow: false
mathjax: false
mindmap: false
mindmap2: false
---
# Memory Expire

因为内存是有限的，如果缓存中的所有数据都是一直保存的话，很容易导致Out of memory。因此缓存中的数据要过期删除和淘汰。



## 内存配置

通过 `CONFIG SET maxmemory 100mb`或者在 `redis.conf` 配置文件设置 `maxmemory 100mb` Redis 内存占用限制。如果`maxmemory` 为 0 ，在 `64` 位「空间」上则没有限制，而 `32` 位「空间」则有 `3GB` 的隐式限制。

在配置文件 redis.conf 中，可以通过参数 `maxmemory <bytes>` 来设定最大运行内存，只有在 Redis 的运行内存达到了我们设置的最大运行内存，才会触发内存淘汰策略。 不同位数的操作系统，maxmemory 的默认值是不同的：

- 在 64 位操作系统中，maxmemory 的默认值是 0，表示没有内存大小限制，那么不管用户存放多少数据到 Redis 中，Redis 也不会对可用内存进行检查，直到 Redis 实例因内存不足而崩溃也无作为。
- 在 32 位操作系统中，maxmemory 的默认值是 3G，因为 32 位的机器最大只支持 4GB 的内存，而系统本身就需要一定的内存资源来支持运行，所以 32 位操作系统限制最大 3 GB 的可用内存是非常合理的，这样可以避免因为内存不足而导致 Redis 实例崩溃。



## 过期删除

Redis缓存数据过期时并不会立马删除，Redis 有两种删除过期数据的策略。

- 定期选取部分数据删除；
- 惰性删除。



> 缓存设置过期还可以用来满足一些有时间限制的需求，如验证码15分钟过期，登陆token在1天内有效。



### 设置过期时间语法

**Redis中除了字符串类型有自己独有设置过期时间的命令 `setex` 外，其他方法都需要依靠 `expire` 命令来设置过期时间 。另外， `persist` 命令可以移除一个键的过期时间：**

从 Redis 版本 7.0.0 开始：`EXPIRE` 添加了选项：`NX`、`XX`和`GT`、`LT` 选项。

- NX：当 key 没有过期时才设置过期时间；
- XX：只有 key 已过期的时候才设置过期时间；
- GT：仅当**新的到期时间**大于当前到期时间时才设置过期时间；
- LT：仅在新到期时间小于当前到期时间才设置到过期时间。



#### String

```bash
setex key 60 value # 数据在 60s 后过期
```



#### 其它类型

```bash
EXPIRE key seconds [ NX | XX | GT | LT]
```



### 数据过期原理

Redis 通过一个叫做过期字典来保存数据过期的时间。过期字典的键指向Redis数据库中的某个key(键)，过期字典的值是一个 long 类型的整数，这个整数保存了key所指向的数据库键的过期时间（毫秒精度的UNIX时间戳）。

字典实际上是哈希表，哈希表的最大好处就是可以用 O(1) 的时间复杂度来快速查找。

当查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：

- 如果不在，则正常读取键值；
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。



```c
typedef struct redisDb {
    ...
    
    dict *dict;     //数据库键空间,保存着数据库中所有键值对
    dict *expires   // 过期字典,保存着键的过期时间
    ...
} redisDb;
```



### 数据过期删除策略

#### 定时删除

**在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。**



定时删除策略的**优点**：

- 可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放。因此，定时删除对内存是最友好的。

定时删除策略的**缺点**：

- 在过期 key 比较多的情况下，删除过期 key 可能会占用相当一部分 CPU 时间，在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。



#### 惰性删除

**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。将删除过期数据的主动权交给了每次访问请求。**



惰性删除策略的**优点**：

- 因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。

惰性删除策略的**缺点**：

- 如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。



##### 实现原理

Redis 的惰性删除策略由 db.c 文件中的 `expireIfNeeded` 函数实现，代码如下：

```c
int expireIfNeeded(redisDb *db, robj *key) {
    // 判断 key 是否过期
    if (!keyIsExpired(db,key)) return 0;
    ....
    /* 删除过期键 */
    ....
    // 如果 server.lazyfree_lazy_expire 为 1 表示异步删除，反之同步删除；
    return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) :
                                         dbSyncDelete(db,key);
}
```



Redis 在访问或者修改 key 之前，都会调用 expireIfNeeded 函数对其进行检查，检查 key 是否过期：

- 如果过期，则删除该 key，至于选择异步删除，还是选择同步删除，根据 `lazyfree_lazy_expire` 参数配置决定（Redis 4.0版本开始提供参数），然后返回 null 客户端；
- 如果没有过期，不做任何处理，然后返回正常的键值对给客户端；



#### 定期删除

**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。**



定期删除策略的**优点**：

- 通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。

定期删除策略的**缺点**：

- 内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。
- 难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。



##### 实现原理

在 Redis 中，默认每秒进行 10 次过期检查一次数据库，此配置可通过 Redis 的配置文件 redis.conf 进行配置，配置键为 hz 它的默认值是 hz 10。

特别强调下，每次检查数据库并不是遍历过期字典中的所有 key，而是从数据库中随机抽取一定数量的 key 进行过期检查。



我查了下源码，定期删除的实现在 expire.c 文件下的 `activeExpireCycle` 函数中，其中随机抽查的数量由 `ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP` 定义的，它是写死在代码中的，数值是 20。

也就是说，数据库每轮抽查时，会随机选择 20 个 key 判断是否过期。

接下来，详细说说 Redis 的定期删除的流程：

1. 从过期字典中随机抽取 20 个 key；
2. 检查这 20 个 key 是否过期，并删除已过期的 key；
3. 如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。

可以看到，定期删除是一个循环的流程。

那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。

伪代码如下：

```c
do {
    //已过期的数量
    expired = 0；
    //随机抽取的数量
    num = 20;
    while (num--) {
        //1. 从过期字典中随机抽取 1 个 key
        //2. 判断该 key 是否过期，如果已过期则进行删除，同时对 expired++
    }
    
    // 超过时间限制则退出
    if (timelimit_exit) return;

  /* 如果本轮检查的已过期 key 的数量，超过 25%，则继续随机抽查，否则退出本轮检查 */
} while (expired > 20/4); 
```



### 总结

定期删除对内存更加友好，惰性删除对CPU更加友好。所以Redis 采用的是 **定期删除+惰性/懒汉式删除** ，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。



## 内存淘汰

但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就Out of memory了。

前面说的过期删除策略，是删除已过期的 key，而当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行。

为了解决这个问题就要用到内存淘汰机制

![图片](https://oss.xubighead.top/oss/image/202506/1930436651277979650.jpg)

### 淘汰策略

Redis 提供8种数据淘汰策略：

| 淘汰策略        | 描述                                                         |
| --------------- | ------------------------------------------------------------ |
| volatile-lru    | （Least Recently Used）（V3.0 前默认）淘汰所有设置了过期时间的键值中，最久未使用的键值；适用于存在不能删除的数据场景。 |
| volatile-lfu    | （Least Frequently Used）（V4.0后）淘汰所有设置了过期时间的键值中，最少使用的键值；适用于 |
| volatile-random | 随机淘汰设置了过期时间的任意键值；                           |
| volatile-ttl    | （Time To Live）优先淘汰更早过期的键值。                     |
| allkeys-lru     | 淘汰整个键值中最久未使用的键值；适用于存在明显的冷热数据区别场景。 |
| allkeys-lfu     | （V4.0后）淘汰整个键值中最少使用的键值。                     |
| allkeys-random  | 随机淘汰任意键值；适用于数据没有明显的冷热分别，所有的数据分布查询比较均衡，这些数据都会被随机查询场景。 |
| no-eviction     | （V3.0 后默认）当运行内存超过最大设置内存时，不淘汰任何数据，新增直接返回错误。 |



#### 相关命令

##### 查看淘汰策略

使用 `config get maxmemory-policy` 命令，来查看当前 Redis 的内存淘汰策略，命令如下：

```bash
> config get maxmemory-policy
1) "maxmemory-policy"
2) "noeviction"
```



##### 修改淘汰策略

- 方式一：通过“`config set maxmemory-policy <策略>`”命令设置。它的优点是设置之后立即生效，不需要重启 Redis 服务，缺点是重启 Redis 之后，设置就会失效。
- 方式二：通过修改 Redis 配置文件修改，设置“`maxmemory-policy <策略>`”，它的优点是重启 Redis 服务后配置不会丢失，缺点是必须重启 Redis 服务，设置才能生效。



#### 总结

- volatile为前缀的策略都是从已过期的数据集中进行淘汰。
- allkeys为前缀的策略都是面向所有key进行淘汰。
- LRU最近最少用到的。
- LFU最不常用的。
- 它们的触发条件都是Redis使用的内存达到阈值时。



### 淘汰算法

#### LRU算法

##### LRU算法概述

**LRU** 全称是 Least Recently Used 翻译为**最近最少使用**，会选择淘汰最近最少使用的数据。

传统 LRU 算法的实现是基于「链表」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。

Redis 并没有使用这样的方式实现 LRU 算法，因为传统的 LRU 算法存在两个问题：

- 需要用链表管理所有的缓存数据，这会带来额外的空间开销；
- 当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。



##### Redis实现

Redis 实现的是一种**近似 LRU 算法**，目的是为了更好的节约内存，它的**实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间**。



```c
typedef struct redisObject {
    ...
      
    // 24 bits，用于记录对象的访问信息
    unsigned lru:24;  
    ...
} robj;
```



Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。



当 Redis 进行内存淘汰时，会使用**随机采样的方式来淘汰数据**，它是随机取 5 个值（此值可配置），然后**淘汰最久没有使用的那个**。

Redis 实现的 LRU 算法的优点：

- 不用为所有的数据维护一个大链表，节省了空间占用；
- 不用在每次数据访问时都移动链表项，提升了缓存的性能；

但是 LRU 算法有一个问题，**无法解决缓存污染问题**，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。



##### LRU算法总结

Redis 在对象结构体中维护了最近访问时间，淘汰采样数据中最久没有使用的数据。存在缓存污染问题。



#### LFU算法

##### LFU算法概述

LFU 全称是 Least Frequently Used 翻译为**最近最不常用的，**LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。

所以， LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些。



##### Redis实现

LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息。Redis 对象的结构如下：



```c
typedef struct redisObject {
    ...
      
    // 24 bits，用于记录对象的访问信息
    unsigned lru:24;  
    ...
} robj;
```



Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。

- ldt 是用来记录 key 的访问时间戳；
- logc 是用来记录 key 的访问频次，它的值越小表示使用频率越低，越容易淘汰，每个新加入的 key 的logc 初始值为 5。



logc 并不是单纯的访问次数，而是访问频次（访问频率），因为 **logc 会随时间推移而衰减的**。

在每次 key 被访问时，会先对 logc 做一个衰减操作，衰减的值跟前后访问时间的差距有关系，如果上一次访问的时间与这一次访问的时间差距很大，那么衰减的值就越大，这样实现的 LFU 算法是根据**访问频率**来淘汰数据的，而不只是访问次数。访问频率需要考虑 key 的访问是多长时间段内发生的。key 的先前访问距离当前时间越长，那么这个 key 的访问频率相应地也就会降低，这样被淘汰的概率也会更大。

对 logc 做完衰减操作后，就开始对 logc 进行增加操作，增加操作并不是单纯的 + 1，而是根据概率增加，如果 logc 越大的 key，它的 logc 就越难再增加。



所以，Redis 在访问 key 时，对于 logc 是这样变化的：

1. 先按照上次访问距离当前的时长，来对 logc 进行衰减；
2. 然后，再按照一定概率增加 logc 的值

redis.conf 提供了两个配置项，用于调整 LFU 算法从而控制 logc 的增长和衰减：

- `lfu-decay-time` 用于调整 logc 的衰减速度，它是一个以分钟为单位的数值，默认值为1，lfu-decay-time 值越大，衰减越慢；
- `lfu-log-factor` 用于调整 logc 的增长速度，lfu-log-factor 值越大，logc 增长越慢。



##### LFU算法总结



## 内存碎片

使用`info memory` 命令获取 Redis 内存相关指标，如下所示：

```bash
127.0.0.1:6379> info memory
# Memory
used_memory:1132832  // Redis 存储数据占用的内存量
used_memory_human:1.08M  // 人类可读形式返回内存总量
used_memory_rss:2977792  // 操作系统角度，进程占用的物理总内存
used_memory_rss_human:2.84M // used_memory_rss 可读性模式展示
used_memory_peak:1183808 // 内存使用的最大值，表示 used_memory 的峰值

used_memory_peak_human:1.13M  // 以可读的格式返回 used_memory_peak的值
used_memory_lua:37888   // Lua 引擎所消耗的内存大小。
used_memory_lua_human:37.00K
maxmemory:2147483648    // 能使用的最大内存值，字节为单位。
maxmemory_human:2.00G  // 可读形式
maxmemory_policy:noeviction // 内存淘汰策略

// used_memory_rss / used_memory 的比值，代表内存碎片率
mem_fragmentation_ratio:2.79
```



Redis 进程内存消耗主要由以下部分组成：

- Redis 自身启动所占用的内存；
- 存储对象数据内存；
- 缓冲区内存：主要由 client-output-buffer-limit 客户端输出缓冲区、复制积压缓冲区、AOF 缓冲区。
- 内存碎片。



Redis 自身空进程占用的内存很小可以忽略不计，对象内存是占比最大的一块，里面存储着所有的数据。

缓冲区内存在大流量场景容易失控，造成 Redis 内存不稳定，需要重点关注。

**内存碎片过大会导致明明有空间可用，但是却无法存储数据。**

**碎片 = used_memory_rss 实际使用的物理内存（RSS 值）除以 used_memory 实际存储数据内存。**



### 产生原因

- 内存分配器的分配策略。
- 键值对的大小不一样和删改操作：Redis 频繁做更新操作、大量过期数据删除，释放的空间（不够连续）无法得到复用，导致碎片率上升。



#### 分配策略

Redis 默认的内存分配器采用 jemalloc，可选的分配器还有：glibc、tcmalloc。

**内存分配器并不能做到按需分配，而是采用固定范围的内存块进行分配。**

例如 8 字节、16 字节…..，2 KB，4KB，当申请内存最近接某个固定值的时候，jemalloc 会给它分配最接近固定值大小的空间。

这样就会出现内存碎片，比如程序只需要 1.5 KB，内存分配器会分配 2KB 空间，那么这 0.5KB 就是碎片。

**这么做的目的是减少内存分配次数**，比如申请 22 字节的空间保存数据，jemalloc 就会分配 32 字节，如果后边还要写入 10 字节，就不需要再向操作系统申请空间了，可以使用之前申请的 32 字节。

**删除 key 的时候，Redis 并不会立马把内存归还给操作系统**，出现这个情况是因为底层内存分配器管理导致，比如大多数已经删除的 key 依然与其他有效的 key 分配在同一个内存页中。

另外，分配器为了复用空闲的内存块，原有 5GB 的数据中删除了 2 GB 后，当再次添加数据到实例中，Redis 的 RSS 会保持稳定，不会增长太多。

因为**内存分配器基本上复用了之前删除释放出来的 2GB 内存。**



#### 键值对大小不一样和删改操作

由于内存分配器是按照固定大小分配内存，所以通常分配的内存空间比实际数据占用的大小多一些，会造成碎片，降低内存的存储效率。

另外，键值对的频繁修改和删除，导致内存空间的扩容和释放，比如原本占用 32 字节的字符串，现在修改为占用 20 字节的字符串，那么释放出的 12 字节就是空闲空间。

如果下一个数据存储请求需要申请 13 字节的字符串，那么刚刚释放的 12 字节空间无法使用，导致碎片。

**碎片最大的问题：空间总量足够大，但是这些内存不是连续的，可能大致无法存储数据。**



### 解决办法

首先要确定是否发生了内存碎片，重点关注前面 `INFO memory` 命令提示的 `mem_fragmentation_ratio` 指标，表示内存碎片率：

mem_fragmentation_ratio = used_memory_rss/ used_memory

如果 1 < 碎片率 < 1.5，可以认为是合理的，而大于 1.5 说明碎片已经超过 50%，需要采取一些手段解决碎片率过大的问题。



#### 重启

最简单的方式就是重启，如果没有开启持久化，数据会丢失。

开启持久化的话，需要使用 RDB 或者 AOF 恢复数据，如果只有一个实例，数据大的话会导致恢复阶段长时间无法提供服务，高可用大打折扣。



#### 自动清理内存碎片

Redis 4.0 版本后，自身提供了一种内存碎片清理机制。

对于 Redis 来说，当一块连续的内存空间被划分为好几块不连续的空间的时候，操作系统先把数据以依次挪动拼接在一块，并释放原来数据占据的空间，形成一块连续空闲内存空间。

**开启自动内存碎片清理**

```
CONFIG SET activedefrag yes
```



**Redis 操作数据的指令是单线程，所以在数据复制移动的时候，只能等待清理碎片完成才能处理请求，造成性能损耗。**

可以通过以下两个参数来控制内存碎片清理和结束时机，避免占用 CPU 过多，减少清理碎片对 Redis 处理请求的性能影响。



清理要同时满足以下两个条件才会触发清理操作。

**清理的条件**

`active-defrag-ignore-bytes 200mb`：内存碎片占用的内存达到 200MB，开始清理；

`active-defrag-threshold-lower 20`：内存碎片的空间占比超过系统分配给 Redis 空间的 20% ，开始清理。



**避免对性能造成影响**

清理时间有了，还需要控制清理对性能的影响。由一项两个设置先分配清理碎片占用的 CPU 资源，保证既能正常清理碎片，又能避免对 Redis 处理请求的性能影响。

`active-defrag-cycle-min 20`：自动清理过程中，占用 CPU 时间的比例不低于 20%，从而保证能正常展开清理任务。

`active-defrag-cycle-max 50`：自动清理过程占用的 CPU 时间比例不能高于 50%，超过的话就立刻停止清理，避免对 Redis 的阻塞，造成高延迟。



如果遇到 Redis 性能变慢，排查下是否由于清理碎片导致，如果是，那就调小 `active-defrag-cycle-max` 的值。



## 扩展

### 集群或主从场景

在集群或主从场景下，为了保证数据一致性，让过期操作正常运行，机器之间的时间必须保证稳定同步，否则就会出现过期时间不准的情况。



比如两台时钟严重不同步的机器发生 RDB 传输， slave 的时间设置为未来的 2000 秒，假如在 master 的一个 key 设置 1000 秒存活，当 Slave 加载 RDB 的时候 key 就会认为该 key 过期（因为 slave 机器时间设置为未来的 2000 s），并不会等待 1000 s 才过期。