---
layout: post
title: 2024-01-02-k8s-tools.md
categories: [Kubernetes 容器编排]
description: 
keywords: k8s-tools.md
mermaid: false
sequence: false
flow: false
mathjax: false
mindmap: false
mindmap2: false
---
# Tools

## Minikube

Minikube 是一个构建单节点集群的工具，是运行 Kubemetes 集群最简单、最快捷的途径。



### Install

同样我们还是用阿里云的下载地址：

```
$ curl -Lo minikube http://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/releases/v1.16.0/minikube-linux-amd64 && chmod +x ./minikube && sudo mv ./minikube /usr/local/bin/minikube
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 53.7M  100 53.7M    0     0  6417k      0  0:00:08  0:00:08 --:--:-- 5776k
```



安装完毕后我们启动集群：

```
$ sudo minikube start --driver=none
     minikube v1.16.0 on Ubuntu 18.04
     Using the none driver based on user configuration

     Exiting due to GUEST_MISSING_CONNTRACK: Sorry, Kubernetes 1.20.0 requires conntrack to be installed in root's path
```



这里有报错，根据提示信息我们需要安装conntrack：

```
$ sudo apt-get install conntrack
```



再次启动，由于第一次启动，minikube会下载很多镜像，所以比较慢。启动成功后的输出如下：

```
$ sudo minikube start --driver=none
😄  minikube v1.16.0 on Ubuntu 18.04
✨  Using the none driver based on existing profile
👍  Starting control plane node minikube in cluster minikube
🔄  Restarting existing none bare metal machine for "minikube" ...
ℹ️  OS release is Ubuntu 18.04 LTS
🐳  Preparing Kubernetes v1.20.0 on Docker 20.10.8 ...
    ▪ kubelet.resolv-conf=/run/systemd/resolve/resolv.conf
    > kubelet.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s
    > kubeadm.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s
    > kubectl.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s
    > kubectl: 38.37 MiB / 38.37 MiB [---------------] 100.00% 2.68 MiB p/s 14s
    > kubeadm: 37.40 MiB / 37.40 MiB [---------------] 100.00% 2.20 MiB p/s 17s
    > kubelet: 108.69 MiB / 108.69 MiB [-------------] 100.00% 4.57 MiB p/s 24s
    ▪ Generating certificates and keys ...
    ▪ Booting up control plane ...
    ▪ Configuring RBAC rules ...
🤹  Configuring local host environment ...

❗  The 'none' driver is designed for experts who need to integrate with an existing VM
💡  Most users should use the newer 'docker' driver instead, which does not require root!
📘  For more information, see: https://minikube.sigs.k8s.io/docs/reference/drivers/none/

❗  kubectl and minikube configuration will be stored in /home/yangye
❗  To use kubectl or minikube commands as your own user, you may need to relocate them. For example, to overwrite your own settings, run:

    ▪ sudo mv /home/yangye/.kube /home/yangye/.minikube $HOME
    ▪ sudo chown -R $USER $HOME/.kube $HOME/.minikube

💡  This can also be done automatically by setting the env var CHANGE_MINIKUBE_NONE_USER=true
🔎  Verifying Kubernetes components...
🌟  Enabled addons: storage-provisioner, default-storageclass
🏄  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```



我们可以看一下当前集群所有资源情况：

```
$ sudo kubectl get all -A
NAMESPACE     NAME                                READY   STATUS    RESTARTS   AGE
kube-system   pod/coredns-54d67798b7-7kshc        1/1     Running   0          100s
kube-system   pod/etcd-ayato                      1/1     Running   0          108s
kube-system   pod/kube-apiserver-ayato            1/1     Running   0          108s
kube-system   pod/kube-controller-manager-ayato   1/1     Running   0          108s
kube-system   pod/kube-proxy-cvb25                1/1     Running   0          100s
kube-system   pod/kube-scheduler-ayato            1/1     Running   0          108s
kube-system   pod/storage-provisioner             1/1     Running   0          113s

NAMESPACE     NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
default       service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP                  117s
kube-system   service/kube-dns     ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   115s

NAMESPACE     NAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
kube-system   daemonset.apps/kube-proxy   1         1         1       1            1           kubernetes.io/os=linux   115s

NAMESPACE     NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
kube-system   deployment.apps/coredns   1/1     1            1           115s

NAMESPACE     NAME                                 DESIRED   CURRENT   READY   AGE
kube-system   replicaset.apps/coredns-54d67798b7   1         1         1       100s
```



在进行操作时，大家可能会遇到集群拉取镜像失败问题导致pod起不来，这个需要在启动minikube时指定国内的镜像仓库：

```
minikube start --vm-driver=none --registry-mirror=https://registry.docker-cn.com
```



### Commands

minikube version：查看版本

minikube status：查看状态

minikube profile list：查看属性

minikube addons list：查看当前支持的插件

minikube service list：查看服务列表

minikube node list：参看添加的node

minikube ssh：登录

minikube ip：获取IP地址

minikube start：启动或重启

minikube stop：停止

minikube delete：删除

minikube dashboard：在默认浏览器中启动仪表盘

rm-rf ~/.minikube：重置(清理所有缓存的镜像）



## Kubectl

为了避免网络问题，我们直接使用阿里云的下载地址：

```sh
$ curl -Lo kubectl http://kubernetes.oss-cn-hangzhou.aliyuncs.com/kubernetes-release/release/v1.20.0/bin/linux/amd64/kubectl && chmod +x ./kubectl && sudo mv ./kubectl /usr/local/bin/kubectl
```



验证是否安装成功：

```sh
$ kubectl version --client
Client Version: version.Info{Major:"1", Minor:"20", GitVersion:"v1.20.0", GitCommit:"af46c47ce925f4c4ad5cc8d1fca46c7b77d13b38", GitTreeState:"clean", BuildDate:"2020-12-08T17:59:43Z", GoVersion:"go1.15.5", Compiler:"gc", Platform:"linux/amd64"}
```



## Flannel

创建覆盖网络。

​

### 配置Flannel（所有节点操作）

安装软件包

```
yum install flannel -y
```

修改配置文件

```
[root@k8s-master ~]# grep "^[a-Z]" /etc/sysconfig/flanneld
FLANNEL_ETCD_ENDPOINTS="http://10.0.0.11:2379"
FLANNEL_ETCD_PREFIX="/atomic.io/network"
```



### 配置etcd中关于flannel的key

Flannel使用Etcd进行配置，来保证多个Flannel实例之间的配置一致性，所以需要在etcd上进行如下配置：（‘/atomic.io/network/config’这个key与上文/etc/sysconfig/flannel中的配置项FLANNEL_ETCD_PREFIX是相对应的，错误的话启动就会出错）



配置网络范围

```
etcdctl mk  /atomic.io/network/config '{ "Network": "172.16.0.0/16" }'
```

操作创建网络

```
[root@k8s-master ~]# etcdctl mk /atomic.io/network/config '{ "Network": "172.16.0.0/16" }'
{ "Network": "172.16.0.0/16" }
```

master节点操作

```
    systemctl enable flanneld.service 
    systemctl start flanneld.service 
    service docker restart
    systemctl restart kube-apiserver.service
    systemctl restart kube-controller-manager.service
    systemctl restart kube-scheduler.service
```

node节点操作

```
    systemctl enable flanneld.service 
    systemctl start flanneld.service 
    service docker restart
    systemctl restart kubelet.service
    systemctl restart kube-proxy.service 
    
```

修改配置文件

```
[root@k8s-master ~]# cat  /etc/kubernetes/apiserver 
KUBE_API_ADDRESS="--insecure-bind-address=0.0.0.0"
KUBE_API_PORT="--port=8080"
KUBE_ETCD_SERVERS="--etcd-servers=http://10.0.0.11:2379"
KUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=10.254.0.0/16"
KUBE_ADMISSION_CONTROL="--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota"
KUBE_API_ARGS=""
```

**至此Flannel****网络配置完成**



## Auto-Completion

auto-completion工具可以提供kubectl命令自动补全功能。

```sh
$ sudo apt update
Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease
Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease
Hit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease
Hit:4 https://download.docker.com/linux/ubuntu bionic InRelease
Hit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease
Reading package lists... Done
Building dependency tree
Reading state information... Done
144 packages can be upgraded. Run 'apt list --upgradable' to see them.

# 安装auto-completion功能
$ sudo apt install bash-completion
Reading package lists... Done
Building dependency tree
Reading state information... Done
bash-completion is already the newest version (1:2.8-1ubuntu1).
0 upgraded, 0 newly installed, 0 to remove and 144 not upgraded.
```



如果是centos系统，则使用**yum install bash-completion -y**命令安装。



配置自动补全

**Bash**：

```sh
source <(kubectl completion bash)
echo "source <(kubectl completion bash)" >> ~/.bashrc
```



**Zsh**：

```sh
source <(kubectl completion zsh)
echo "[[ $commands[kubectl] ]] && source <(kubectl completion zsh)" >> ~/.zshrc
```

配置后就可以通过Tab键自动补全命令啦！



## Kubectx

kubectx提供切换context和namespace功能。

```sh
# 安装kubectx
$ sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
Cloning into '/opt/kubectx'...
remote: Enumerating objects: 1457, done.
remote: Counting objects: 100% (172/172), done.
remote: Compressing objects: 100% (115/115), done.
remote: Total 1457 (delta 85), reused 97 (delta 51), pack-reused 1285
Receiving objects: 100% (1457/1457), 905.30 KiB | 69.00 KiB/s, done.
Resolving deltas: 100% (817/817), done.
$ sudo ln -s /opt/kubectx/kubens /usr/local/bin/kubectl-ns
$ sudo ln -s /opt/kubectx/kubectx /usr/local/bin/kubectl-ctx
```



```sh
$ sudo kubectl ctx
minikube
$ sudo kubectl ctx minikube
Switched to context "minikube".
$ sudo kubectl ns
default
kube-node-lease
kube-public
kube-system
kubernetes-dashboard
$ sudo kubectl ns kube-public
Context "minikube" modified.
Active namespace is "kube-public".
$ sudo kubectl ns default
Context "minikube" modified.
Active namespace is "default".
```



## Stern

stern这个工具它具备如下能力：

- 允许使用正则表达式来选择需要查看的PodName
- 为不同 Pod 的日志展示不同的颜色
- 跟踪日志过程中假如有符合规则的新 Pod 被创建, 那么会自动添加到输出中



首先安装stern（下载stern时可能较慢可以多试几次）：

```sh
wget https://github.com/wercker/stern/releases/download/1.11.0/stern_linux_amd64
sudo mv stern_linux_amd64 /usr/local/bin/kubectl-tail
sudo chomd +x /usr/local/bin/kubectl-tail
```



Pod里面有两个容器：webapp和busybox，如果使用kubectl logs 还得指定具体的容器，而使用stern就没有这样的限制。

```sh
$ sudo k tail .
+ webapp › busybox
+ webapp › webapp
webapp busybox 14:04:53.197 [INFO ] [main] [org.apache.coyote.http11.Http11NioProtocol] Initializing ProtocolHandler ["http-nio-4567"]
webapp busybox 14:04:53.200 [INFO ] [main] [org.apache.catalina.core.StandardService] Starting service [Tomcat]
webapp busybox 14:04:53.201 [INFO ] [main] [org.apache.catalina.core.StandardEngine] Starting Servlet engine: [Apache Tomcat/9.0.41]
webapp busybox 14:04:53.324 [INFO ] [main] [org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/]] Initializing Spring embedded WebApplicationContext
webapp busybox 14:04:53.325 [INFO ] [main] [org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext] Root WebApplicationContext: initialization completed in 2952 ms
webapp busybox 14:04:53.801 [INFO ] [main] [org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor] Initializing ExecutorService 'applicationTaskExecutor'
webapp busybox 14:04:54.264 [WARN ] [main] [org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration] Cannot find template location: classpath:/templates/ (please add some templates or check your Thymeleaf configuration)
webapp busybox 14:04:54.377 [INFO ] [main] [org.apache.coyote.http11.Http11NioProtocol] Starting ProtocolHandler ["http-nio-4567"]
webapp busybox 14:04:54.481 [INFO ] [main] [org.springframework.boot.web.embedded.tomcat.TomcatWebServer] Tomcat started on port(s): 4567 (http) with context path ''
webapp busybox 14:04:54.509 [INFO ] [main] [org.demo.webapp.todolist.TodoListApplication] Started TodoListApplication in 6.235 seconds (JVM running for 8.074)
webapp webapp
webapp webapp   .   ____          _            __ _ _
webapp webapp  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
webapp webapp ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
webapp webapp  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
webapp webapp   '  |____| .__|_| |_|_| |_\__, | / / / /
webapp webapp  =========|_|==============|___/=/_/_/_/
webapp webapp  :: Spring Boot ::                (v2.4.2)
webapp webapp
webapp webapp 14:04:50.124 [INFO ] [main] [org.demo.webapp.todolist.TodoListApplication] Starting TodoListApplication v1.0-SNAPSHOT using Java 1.8.0_111 on webapp with PID 1 (/opt/soft/webapp.jar started by root in /opt/soft)
webapp webapp 14:04:50.165 [INFO ] [main] [org.demo.webapp.todolist.TodoListApplication] No active profile set, falling back to default profiles: default
webapp webapp 14:04:53.158 [INFO ] [main] [org.springframework.boot.web.embedded.tomcat.TomcatWebServer] Tomcat initialized with port(s): 4567 (http)
webapp webapp 14:04:53.197 [INFO ] [main] [org.apache.coyote.http11.Http11NioProtocol] Initializing ProtocolHandler ["http-nio-4567"]
webapp webapp 14:04:53.200 [INFO ] [main] [org.apache.catalina.core.StandardService] Starting service [Tomcat]
webapp webapp 14:04:53.201 [INFO ] [main] [org.apache.catalina.core.StandardEngine] Starting Servlet engine: [Apache Tomcat/9.0.41]
webapp webapp 14:04:53.324 [INFO ] [main] [org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/]] Initializing Spring embedded WebApplicationContext
webapp webapp 14:04:53.325 [INFO ] [main] [org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext] Root WebApplicationContext: initialization completed in 2952 ms
webapp webapp 14:04:53.801 [INFO ] [main] [org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor] Initializing ExecutorService 'applicationTaskExecutor'
webapp webapp 14:04:54.264 [WARN ] [main] [org.springframework.boot.autoconfigure.thymeleaf.ThymeleafAutoConfiguration$DefaultTemplateResolverConfiguration] Cannot find template location: classpath:/templates/ (please add some templates or check your Thymeleaf configuration)
webapp webapp 14:04:54.377 [INFO ] [main] [org.apache.coyote.http11.Http11NioProtocol] Starting ProtocolHandler ["http-nio-4567"]
webapp webapp 14:04:54.481 [INFO ] [main] [org.springframework.boot.web.embedded.tomcat.TomcatWebServer] Tomcat started on port(s): 4567 (http) with context path ''
webapp webapp 14:04:54.509 [INFO ] [main] [org.demo.webapp.todolist.TodoListApplication] Started TodoListApplication in 6.235 seconds (JVM running for 8.074)
```



## metric-server

创建目录，用来存放metric-server

```shell
[root@k8scloude1 ~]# mkdir metric-server

[root@k8scloude1 ~]# cd metric-server/
```



下载metrics-server并解压

```shell
[root@k8scloude1 metric-server]# wget https://github.com/kubernetes-sigs/metrics-server/archive/v0.3.6.tar.gz

[root@k8scloude1 metric-server]# ls
v0.3.6.tar.gz

[root@k8scloude1 metric-server]# tar xf v0.3.6.tar.gz 

[root@k8scloude1 metric-server]# ls
metrics-server-0.3.6  v0.3.6.tar.gz

[root@k8scloude1 metric-server]# cd metrics-server-0.3.6/

[root@k8scloude1 metrics-server-0.3.6]# ls
cmd  code-of-conduct.md  CONTRIBUTING.md  deploy  Gopkg.lock  Gopkg.toml  hack  LICENSE  Makefile  OWNERS  OWNERS_ALIASES  pkg  README.md  SECURITY_CONTACTS  vendor  version

[root@k8scloude1 metrics-server-0.3.6]# cd deploy/

[root@k8scloude1 deploy]# ls
1.7  1.8+  docker  minikube

[root@k8scloude1 deploy]# cd 1.8+

[root@k8scloude1 1.8+]# ls
aggregated-metrics-reader.yaml  auth-delegator.yaml  auth-reader.yaml  metrics-apiservice.yaml  metrics-server-deployment.yaml  metrics-server-service.yaml  resource-reader.yaml
```



查看需要下载的镜像，image: k8s.gcr.io/metrics-server-amd64:v0.3.6这个镜像国内访问不了，我们手动下载一个国内镜像

```shell
[root@k8scloude1 1.8+]# grep image metrics-server-deployment.yaml
      # mount in tmp so we can safely use from-scratch images and/or read-only containers
        image: k8s.gcr.io/metrics-server-amd64:v0.3.6
        imagePullPolicy: Always
```



在k8s集群master节点和worker节点都需要下载metrics-server-amd64:v0.3.6镜像

```shell
[root@k8scloude1 1.8+]# docker pull mirrorgooglecontainers/metrics-server-amd64:v0.3.6

[root@k8scloude1 1.8+]# docker images | grep mirrorgooglecontainers
REPOSITORY                                                        TAG        IMAGE ID       CREATED         SIZE
mirrorgooglecontainers/metrics-server-amd64                       v0.3.6     9dd718864ce6   2 years ago     39.9MB
```



镜像已经下好了，现在进行docker tag重命名，并删除原镜像mirrorgooglecontainers/metrics-server-amd64:v0.3.6

```shell
[root@k8scloude1 1.8+]# docker tag mirrorgooglecontainers/metrics-server-amd64:v0.3.6 k8s.gcr.io/metrics-server-amd64:v0.3.6

[root@k8scloude1 1.8+]# docker rmi mirrorgooglecontainers/metrics-server-amd64:v0.3.6
```



worker节点也进行相同操作

```shell
[root@k8scloude2 ~]# docker pull mirrorgooglecontainers/metrics-server-amd64:v0.3.6

[root@k8scloude2 ~]# docker tag mirrorgooglecontainers/metrics-server-amd64:v0.3.6 k8s.gcr.io/metrics-server-amd64:v0.3.6

[root@k8scloude2 ~]# docker rmi mirrorgooglecontainers/metrics-server-amd64:v0.3.6

[root@k8scloude3 ~]# docker pull mirrorgooglecontainers/metrics-server-amd64:v0.3.6

[root@k8scloude3 ~]# docker tag mirrorgooglecontainers/metrics-server-amd64:v0.3.6 k8s.gcr.io/metrics-server-amd64:v0.3.6

[root@k8scloude3 ~]# docker rmi mirrorgooglecontainers/metrics-server-amd64:v0.3.6
```



修改配置文件，镜像下载策略imagePullPolicy改为IfNotPresent，IfNotPresent表示只有当镜像在本地不存在时才会拉取

```shell
[root@k8scloude1 1.8+]# pwd
/root/metric-server/metrics-server-0.3.6/deploy/1.8+

#修改内容如下： imagePullPolicy: IfNotPresent
#        command:
#      - /metrics-server
#        - --metric-resolution=30s
#        - --kubelet-insecure-tls
#        - --kubelet-preferred-address-types=InternalIP
[root@k8scloude1 1.8+]# tail -20 metrics-server-deployment.yaml
        k8s-app: metrics-server
    spec:
      serviceAccountName: metrics-server
      volumes:
      # mount in tmp so we can safely use from-scratch images and/or read-only containers
      - name: tmp-dir
        emptyDir: {}
      containers:
      - name: metrics-server
        image: k8s.gcr.io/metrics-server-amd64:v0.3.6
        imagePullPolicy: IfNotPresent
        command:
        - /metrics-server
        - --metric-resolution=30s
        - --kubelet-insecure-tls
        - --kubelet-preferred-address-types=InternalIP
        volumeMounts:
        - name: tmp-dir
          mountPath: /tmp
```



安装metrics-server

```shell
#kubectl apply -f .    .表示安装当前目录下的所有文件
[root@k8scloude1 1.8+]# kubectl apply -f .
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
Warning: rbac.authorization.k8s.io/v1beta1 ClusterRoleBinding is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 ClusterRoleBinding
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
Warning: rbac.authorization.k8s.io/v1beta1 RoleBinding is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 RoleBinding
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
Warning: apiregistration.k8s.io/v1beta1 APIService is deprecated in v1.19+, unavailable in v1.22+; use apiregistration.k8s.io/v1 APIService
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
serviceaccount/metrics-server created
deployment.apps/metrics-server created
service/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
```



查看所有的命名空间

```shell
[root@k8scloude1 1.8+]# kubectl get ns
NAME              STATUS   AGE
default           Active   18h
kube-node-lease   Active   18h
kube-public       Active   18h
kube-system       Active   18h
```



当观察到metrics-server-bcfb98c76-k5dmj状态为Running，metrics-server服务就正常启动了

```shell
[root@k8scloude1 1.8+]# kubectl get pod -n kube-system -o wide
NAME                                       READY   STATUS    RESTARTS   AGE   IP                NODE         NOMINATED NODE   READINESS GATES
calico-kube-controllers-6b9fbfff44-4jzkj   1/1     Running   2          19h   10.244.251.194    k8scloude3   <none>           <none>
calico-node-bdlgm                          1/1     Running   1          19h   192.168.110.130   k8scloude1   <none>           <none>
calico-node-hx8bk                          1/1     Running   1          19h   192.168.110.128   k8scloude3   <none>           <none>
calico-node-nsbfs                          1/1     Running   1          19h   192.168.110.129   k8scloude2   <none>           <none>
coredns-545d6fc579-7wm95                   1/1     Running   1          19h   10.244.158.68     k8scloude1   <none>           <none>
coredns-545d6fc579-87q8j                   1/1     Running   1          19h   10.244.158.67     k8scloude1   <none>           <none>
etcd-k8scloude1                            1/1     Running   1          19h   192.168.110.130   k8scloude1   <none>           <none>
kube-apiserver-k8scloude1                  1/1     Running   1          19h   192.168.110.130   k8scloude1   <none>           <none>
kube-controller-manager-k8scloude1         1/1     Running   1          19h   192.168.110.130   k8scloude1   <none>           <none>
kube-proxy-599xh                           1/1     Running   1          19h   192.168.110.128   k8scloude3   <none>           <none>
kube-proxy-lpj8z                           1/1     Running   1          19h   192.168.110.129   k8scloude2   <none>           <none>
kube-proxy-zxlk9                           1/1     Running   1          19h   192.168.110.130   k8scloude1   <none>           <none>
kube-scheduler-k8scloude1                  1/1     Running   1          19h   192.168.110.130   k8scloude1   <none>           <none>
metrics-server-bcfb98c76-k5dmj             1/1     Running   0          70s   10.244.112.131    k8scloude2   <none>           <none>
```



## kubens

默认的切换命名空间的命令不好用，可以使用第三方的命名空间切换工具：**kubens**，kubens命令所在的网站为：https://github.com/ahmetb/kubectx/releases/。

下载kubens，并授予可执行权限

```shell
[root@k8scloude1 ~]# wget https://github.com/ahmetb/kubectx/releases/download/v0.9.4/kubens

[root@k8scloude1 ~]# ll -h kubens 
-rw-r--r-- 1 root root 5.5K 12月  8 15:46 kubens

[root@k8scloude1 ~]# chmod +x kubens 

[root@k8scloude1 ~]# mv kubens /bin/

[root@k8scloude1 ~]# ls /bin/kubens 
/bin/kubens
```