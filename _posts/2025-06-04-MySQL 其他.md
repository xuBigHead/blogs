---
layout: post
title: MySQL 其他.md
categories: [MySQL]
description: MySQL
keywords: MySQL
mermaid: false
sequence: false
flow: false
mathjax: false
mindmap: false
mindmap2: false
---
# MySQL内存结构

### 脏页

当我们要往数据库插入一条数据、或者要更新一条数据的时候，我们知道数据库会在**内存**中把对应字段的数据更新了，但是更新之后，这些更新的字段并不会马上同步持久化到**磁盘**中去，而是把这些更新的记录写入到 redo log 日记中去，等到空闲的时候，在通过 redo log 里的日记把最新的数据同步到**磁盘**中去。

当内存数据页跟磁盘数据页内容不一致的时候，称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。



#### 刷新脏页

引入了 Buffer Pool 后，当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，但是磁盘中还是原数据。

因此，脏页需要被刷入磁盘，保证缓存和磁盘数据一致，但是若每次修改数据都刷入磁盘，则性能会很差，因此一般都会在一定时机进行批量刷盘。

可能大家担心，如果在脏页还没有来得及刷入到磁盘时，MySQL 宕机了，不就丢失数据了吗？

这个不用担心，InnoDB 的更新操作采用的是 Write Ahead Log 策略，即先写日志，再写入磁盘，通过 redo log 日志让 MySQL 拥有了崩溃恢复能力。



**刷脏页有下面4种场景（后两种不用太关注“性能”问题）：**

- **redolog写满了：**redo log 里的容量是有限的，如果数据库一直很忙，更新又很频繁，这个时候 redo log 很快就会被写满了，这个时候就没办法等到空闲的时候再把数据同步到磁盘的，只能暂停其他操作，全身心来把数据同步到磁盘中去的，而这个时候，**就会导致我们平时正常的SQL语句突然执行的很慢**，所以说，数据库在在同步数据到磁盘的时候，就有可能导致我们的SQL语句执行的很慢了。
- **内存不够用了：**如果一次查询较多的数据，恰好碰到所查数据页不在内存中时，需要申请内存，而此时恰好内存不足的时候就需要淘汰一部分内存数据页，如果是干净页，就直接释放，如果恰好是脏页就需要刷脏页。
- **MySQL 认为系统“空闲”的时候：**这时系统没什么压力。
- **MySQL 正常关闭的时候：**这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。



#### 脏页管理

设计 Buffer Pool 除了能提高读性能，还能提高写性能，也就是更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为**脏页**，然后再由后台线程将脏页写入到磁盘。

那为了能快速知道哪些缓存页是脏的，于是就设计出 **Flush 链表**，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。

![img](https://oss.xubighead.top/oss/image/202506/1930158510995247106.png)



有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。



### BufferPool

![图片](https://oss.xubighead.top/oss/image/202506/1930158595116208130.jpg)

MySQL 的数据都是存在磁盘中的，那么我们要更新一条记录的时候，得先要从磁盘读取该记录，然后在内存中修改这条记录。那修改完这条记录是选择直接写回到磁盘，还是选择缓存起来呢？

当然是缓存起来好，这样下次有查询语句命中了这条记录，直接读取缓存中的记录，就不需要从磁盘获取数据了。

为此，Innodb 存储引擎设计了一个**缓冲池（Buffer Pool）**，来提高数据库的读写性能。



<img src="https://oss.xubighead.top/oss/image/202506/1930158656344657921.png" alt="Buffer Poo" style="zoom:50%;" />

有了 Buffer Pool 后：

- 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。
- 当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。



应用系统分层架构，为了加速数据访问，会把最常访问的数据，放在缓存(cache)里，避免每次都去访问数据库。操作系统，会有缓冲池(buffer pool)机制，避免每次访问磁盘，以加速数据的访问。MySQL作为一个存储系统，同样具有缓冲池(buffer pool)机制，以避免每次查询数据都进行磁盘IO，主要作用：

> 1、存在的意义是加速查询 
>
> 2、缓冲池(buffer pool) 是一种常见的**降低磁盘访问** 的机制；
>
> 3、缓冲池通常以页(page **16K**)为单位缓存数据；
>
> 4、缓冲池的常见管理算法是**LRU**，memcache，OS，InnoDB都使用了这种算法；
>
> 5、InnoDB对普通LRU进行了优化：将缓冲池分为`老生代`和`新生代`，入缓冲池的页，优先进入老生代，该页被访问，才进入新生代，以解决预读失效的问题页被访问。且在老生代**停留时间超过配置阈值**的，才进入新生代，以解决批量数据访问，大量热数据淘汰的问题



#### 缓存池大小

Buffer Pool 是在 MySQL 启动的时候，向操作系统申请的一片连续的内存空间，默认配置下 Buffer Pool 只有 `128MB` 。

可以通过调整 `innodb_buffer_pool_size` 参数来设置 Buffer Pool 的大小，一般建议设置成可用物理内存的 60%~80%。



#### 缓存池内容

InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，Buffer Pool 同样需要按「页」来划分。

InnoDB中，因为直接操作磁盘会比较慢，所以加了一层内存提提速，叫**buffer pool**，这里面，放了很多内存页，每一页16KB，有些内存页放的是数据库表里看到的那种一行行的数据，有些则是放的索引信息。

在 MySQL 启动的时候，**InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的`16KB`的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页**。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。

所以，MySQL 刚启动的时候，你会观察到使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，申请物理内存，接着将虚拟地址和物理地址建立映射关系。

Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等等。

<img src="https://oss.xubighead.top/oss/image/202506/1930158754696892417.png" alt="img" style="zoom:50%;" />



为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个**控制块**，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。

控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页，如下图：

![img](https://oss.xubighead.top/oss/image/202506/1930158795780100097.png)



上图中控制块和缓存页之间灰色部分称为碎片空间。



##### 碎片空间

每一个控制块都对应一个缓存页，那在分配足够多的控制块和缓存页后，可能剩余的那点儿空间不够一对控制块和缓存页的大小，自然就用不到喽，这个用不到的那点儿内存空间就被称为碎片了。

当然，如果把 Buffer Pool 的大小设置的刚刚好的话，也可能不会产生碎片。



##### Undo页

开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。



**查询一条记录，就只需要缓冲一条记录吗？**

不是的。当我们查询一条记录时，当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。



#### 缓存池管理

Buffer Pool 是一片连续的内存空间，当 MySQL 运行一段时间后，这片连续的内存空间中的缓存页既有空闲的，也有被使用的。

那当我们从磁盘读取数据的时候，总不能通过遍历这一片连续的内存空间来找到空闲的缓存页吧，这样效率太低了。

所以，为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 **Free 链表**（空闲链表）。

![img](https://oss.xubighead.top/oss/image/202506/1930158854194171905.png)



Free 链表上除了有控制块，还有一个头节点，该头节点包含链表的头节点地址，尾节点地址，以及当前链表中节点的数量等信息。

Free 链表节点是一个一个的控制块，而每个控制块包含着对应缓存页的地址，所以相当于 Free 链表节点都对应一个空闲的缓存页。

有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。



#### 缓存命中率

Buffer Pool 的大小是有限的，对于一些频繁访问的数据我们希望可以一直留在 Buffer Pool 中，而一些很少访问的数据希望可以在某些时机可以淘汰掉，从而保证 Buffer Pool 不会因为满了而导致无法再缓存新的数据，同时还能保证常用数据留在 Buffer Pool 中。

要实现这个，最容易想到的就是 LRU（Least recently used）算法。

该算法的思路是，链表头部的节点是最近使用的，而链表末尾的节点是最久没被使用的。那么，当空间不够了，就淘汰最久没被使用的节点，从而腾出空间。

简单的 LRU 算法的实现思路是这样的：

- 当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。
- 当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点。



到这里我们可以知道，Buffer Pool 里有三种页和链表来管理数据。

![img](https://oss.xubighead.top/oss/image/202506/1930158904622288897.png)

图中：

- Free Page（空闲页），表示此页未被使用，位于 Free 链表；
- Clean Page（干净页），表示此页已被使用，但是页面未发生修改，位于LRU 链表。
- Dirty Page（脏页），表示此页「已被使用」且「已经被修改」，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成了干净页。脏页同时存在于 LRU 链表和 Flush 链表。

简单的 LRU 算法并没有被 MySQL 使用，因为简单的 LRU 算法无法避免下面这两个问题：

- 预读失效；
- Buffer Pool 污染；



##### 查看缓存命中率

```
SHOW STATUS LIKE 'Innodb_buffer_pool_%'
```



`Innodb_buffer_pool_read_requests`表示读请求的次数。

`Innodb_buffer_pool_reads` 表示从物理磁盘中读取数据的请求次数。

所以buffer pool的命中率就可以这样得到：

命中率 = 1 - (Innodb_buffer_pool_reads/Innodb_buffer_pool_read_requests) * 100%



一般情况下**buffer pool命中率**都在`99%`以上，如果低于这个值，才需要考虑加大innodb buffer pool的大小。



##### 预读失效

由于预读(Read-Ahead)，提前把页放入了缓冲池，但最终MySQL并没有从页中读取数据，称为预读失效。

程序是有空间局部性的，靠近当前被访问数据的数据，在未来很大概率会被访问到。所以，MySQL 在加载数据页时，会提前把它相邻的数据页一并加载进来，目的是为了减少磁盘 IO。但是可能这些**被提前加载进来的数据页，并没有被访问**，相当于这个预读是白做了，这个就是**预读失效**。

如果使用简单的 LRU 算法，就会把预读页放到 LRU 链表头部，而当 Buffer Pool空间不够的时候，还需要把末尾的页淘汰掉。如果这些预读页如果一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率。



###### LRU算法改进

要避免预读失效带来影响，最好就是**让预读的页停留在 Buffer Pool 里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在 Buffer Pool 里的时间尽可能长**。

MySQL 改进了 LRU 算法，将 LRU 划分了 2 个区域：**old 区域 和 young 区域**。young 区域在 LRU 链表的前半部分，old 区域则是在后半部分，如下图：

![img](https://oss.xubighead.top/oss/image/202506/1930158972150583298.png)



old 区域占整个 LRU 链表长度的比例可以通过 `innodb_old_blocks_pc` 参数来设置，默认是 37，代表整个 LRU 链表中 young 区域与 old 区域比例是 63:37。

**划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部**。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。



###### 示例

现在有个编号为 20 的页被预读了，这个页只会被插入到 old 区域头部，而 old 区域末尾的页（10号）会被淘汰掉。

![img](https://oss.xubighead.top/oss/image/202506/1930158989603082241.png)

如果 20 号页一直不会被访问，它也没有占用到 young 区域的位置，而且还会比 young 区域的数据更早被淘汰出去。

如果 20 号页被预读后，立刻被访问了，那么就会将它插入到 young 区域的头部，young 区域末尾的页（7号），会被挤到 old 区域，作为 old 区域的头部，这个过程并不会有页被淘汰。

![img](https://oss.xubighead.top/oss/image/202506/1930159006711648258.png)



##### Buffer Pool 污染

当某一个SQL语句，要批量扫描大量数据时，可能导致把缓冲池的所有页都替换出去，导致大量热数据被换出，MySQL性能急剧下降，这种情况叫缓冲池污染。解决办法：加入`老生代停留时间窗口`策略后，短时间内被大量加载的页，并不会立刻插入新生代头部，而是优先淘汰那些，短期内仅仅访问了一次的页。



当某一个 SQL 语句**扫描了大量的数据**时，在 Buffer Pool 空间比较有限的情况下，可能会将 **Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了**，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 **Buffer Pool 污染**。

注意， Buffer Pool 污染并不只是查询语句查询出了大量的数据才出现的问题，即使查询出来的结果集很小，也会造成 Buffer Pool 污染。

比如，在一个数据量非常大的表，执行了这条语句：

```sql
select * from t_user where name like "%xiaolin%";
```

可能这个查询出来的结果就几条记录，但是由于这条语句会发生索引失效，所以这个查询过程是全表扫描的，接着会发生如下的过程：

- 从磁盘读到的页加入到 LRU 链表的 old 区域头部；
- 当从页里读取行记录时，也就是页被访问的时候，就要将该页放到 young 区域头部；
- 接下来拿行记录的 name 字段和字符串 xiaolin 进行模糊匹配，如果符合条件，就加入到结果集里；
- 如此往复，直到扫描完表中的所有记录。

经过这一番折腾，原本 young 区域的热点数据都会被替换掉。



###### 访问时间校验

像前面这种全表扫描的查询，很多缓冲页其实只会被访问一次，但是它却只因为被访问了一次而进入到 young 区域，从而导致热点数据被替换了。

LRU 链表中 young 区域就是热点数据，只要我们提高进入到 young 区域的门槛，就能有效地保证 young 区域里的热点数据不会被替换掉。

MySQL 是这样做的，进入到 young 区域条件增加了一个**停留在 old 区域的时间判断**。

具体是这样做的，在对某个处在 old 区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间：

- 如果后续的访问时间与第一次访问的时间**在某个时间间隔内**，那么**该缓存页就不会被从 old 区域移动到 young 区域的头部**；
- 如果后续的访问时间与第一次访问的时间**不在某个时间间隔内**，那么**该缓存页移动到 young 区域的头部**；

这个间隔时间是由 `innodb_old_blocks_time` 控制的，默认是 1000 ms。

也就说，**只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部**，这样就解决了 Buffer Pool 污染的问题 。

另外，MySQL 针对 young 区域其实做了一个优化，为了防止 young 区域节点频繁移动到头部。young 区域前面 1/4 被访问不会移动到链表头部，只有后面的 3/4被访问了才会。



###### 示例

举个例子，假设需要批量扫描：21，22，23，24，25 这五个页，这些页都会被逐一访问（读取页里的记录）。

![img](https://oss.xubighead.top/oss/image/202506/1930159088517353474.png)

在批量访问这些数据的时候，会被逐一插入到 young 区域头部。

![img](https://oss.xubighead.top/oss/image/202506/1930159104946442242.png)

可以看到，原本在 young 区域的热点数据 6 和 7 号页都被淘汰了，这就是 Buffer Pool 污染的问题。





## 总结

Innodb 存储引擎设计了一个**缓冲池（\*Buffer Pool\*）**，来提高数据库的读写性能。

Buffer Pool 以页为单位缓冲数据，可以通过 `innodb_buffer_pool_size` 参数调整缓冲池的大小，默认是 128 M。

Innodb 通过三种链表来管理缓页：

- Free List （空闲页链表），管理空闲页；
- Flush List （脏页链表），管理脏页；
- LRU List，管理脏页+干净页，将最近且经常查询的数据缓存在其中，而不常查询的数据就淘汰出去。；

InnoDB 对 LRU 做了一些优化，我们熟悉的 LRU 算法通常是将最近查询的数据放到 LRU 链表的头部，而 InnoDB 做 2 点优化：

- 将 LRU 链表 分为**young 和 old 两个区域**，加入缓冲池的页，优先插入 old 区域；页被访问时，才进入 young 区域，目的是为了解决预读失效的问题。
- 当**「页被访问」且「 old 区域停留时间超过 `innodb_old_blocks_time` 阈值（默认为1秒）」**时，才会将页插入到 young 区域，否则还是插入到 old 区域，目的是为了解决批量数据访问，大量热数据淘汰的问题。

可以通过调整 `innodb_old_blocks_pc` 参数，设置 young 区域和 old 区域比例。

在开启了慢 SQL 监控后，如果你发现「偶尔」会出现一些用时稍长的 SQL，这可因为脏页在刷新到磁盘时导致数据库性能抖动。如果在很短的时间出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小。



# MySQL命令

- 启动：

net start mySql;



- 进入：

mysql -u root -p/mysql -h localhost -u root -p databaseName;



- 备份数据库：(将数据库test备份)：

mysqldump -u root -p test>c:\test.txt



- 将备份数据导入到数据库：(导回test数据库)：

mysql -u root -p test<c:\test.txt



- 删除student_course数据库中的students数据表：

rm -f student_course/students.*



## mysqldump



# MySQL配置

## 配置变量

### profiling

记录SQL执行流程配置，可以查看SQL执行具体耗时。



```sql
# 查看profiling配置是否打开
show variables like 'profiling';
# 开启profiling配置
set profiling=ON;
```



```sql
# 查看所有SQL执行耗时
show profiles;
```

执行结果如下：

| Query_ID | Duration   | Query                            |
| -------- | ---------- | -------------------------------- |
| 1        | 0.06811025 | select * from user where age>=60 |



```sql
# 查看指定SQL执行耗时
show profile for query <Query_ID>;
```

执行结果如下：

| Status               | Duration |
| -------------------- | -------- |
| starting             | 0.000074 |
| checking permissions | 0.000010 |
| Opening tables       | 0.000034 |
| init                 | 0.000032 |
| System lock          | 0.000027 |
| optimizing           | 0.000020 |
| statistics           | 0.000058 |
| preparing            | 0.000018 |
| executing            | 0.000013 |
| Sending data         | 0.067701 |
| end                  | 0.000021 |
| query end            | 0.000015 |
| closing tables       | 0.000014 |
| freeing items        | 0.000047 |
| cleaning up          | 0.000027 |



耗时大部分时候都在`Sending data`阶段，而这一阶段里如果慢的话，最容易想到的还是索引相关的原因。



### max_connections

max_connections表示数据库连接数，Mysql的最大连接数默认是`100`, 最大可以达到`16384`。

```sql
show variables like 'max_connections';

set global max_connections= 500;
```



mysql的server层里有个**连接管理**，它的作用是管理客户端和mysql之间的长连接。

正常情况下，客户端与server层如果只有**一条**连接，那么在执行sql查询之后，只能阻塞等待结果返回，如果有大量查询同时并发请求，那么**后面的请求都需要等待前面的请求执行完成**后，才能开始执行。

SQL执行较慢时可以查看是否是因为连接数过小导致。



### innodb_buffer_pool_size

```sql
show global variables like 'innodb_buffer_pool_size';
set global innodb_buffer_pool_size = 536870912;
```



## 数据库连接

### 查看数据库连接

```sql
# 查看当前 MySQL 连接情况
show processlist;
show full processlist;
```



返回参数如下：

1. **id**：线程ID，可以用`kill id`杀死某个线程

2. **db**：数据库名称

3. **user**：数据库用户

4. **host**：数据库实例的IP

5. **command**：当前执行的命令，比如`Sleep`，`Query`，`Connect`等

6. **time**：消耗时间，单位秒

7. **state**：执行状态，主要有以下状态：

8. - `Sleep`，线程正在等待客户端发送新的请求
	- `Locked`，线程正在等待锁
	- `Sending data`，正在处理`SELECT`查询的记录，同时把结果发送给客户端
	- `Kill`，正在执行`kill`语句，杀死指定线程
	- `Connect`，一个从节点连上了主节点
	- `Quit`，线程正在退出
	- `Sorting for group`，正在为`GROUP BY`做排序
	- `Sorting for order`，正在为`ORDER BY`做排序

9. **info**：正在执行的`SQL`语句



### 空闲连接

当连接详情的 Command 列的状态为 Sleep ，这意味着该连接没有再执行过任何命令，也就是说这是一个空闲的连接，并且空闲的时长是 736 秒（ Time 列）。

MySQL 定义了空闲连接的最大空闲时长，由 wait_timeout 参数控制的，默认值是 8 小时（28880秒），如果空闲连接超过了这个时间，连接器就会自动将它断开。

```sql
> show variables like 'wait_timeout'
```



查询结果：

| Variable_name | Value |
| ------------- | ----- |
| wait_timeout  | 28800 |



也可以手动断开空闲的连接，使用的是 kill connection + id 的命令。

```sql
> kill connection +6;
```



一个处于空闲状态的连接被服务端主动断开后，这个客户端并不会马上知道，等到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。



### 连接限制

MySQL 服务支持的最大连接数由 max_connections 参数控制，默认是 151 个，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。

```sql
> show variables like 'max_connections';
```



### 长连接占用

MySQL 的连接也跟 HTTP 一样，有短连接和长连接的概念，它们的区别如下：

```bash
// 短连接
连接 mysql 服务（TCP 三次握手）
执行sql
断开 mysql 服务（TCP 四次挥手）

// 长连接
连接 mysql 服务（TCP 三次握手）
执行sql
执行sql
执行sql
....
断开 mysql 服务（TCP 四次挥手）
```



使用长连接的好处就是可以减少建立连接和断开连接的过程，所以一般是推荐使用长连接。

但是，使用长连接后可能会占用内存增多，因为 MySQL 在执行查询过程中临时使用内存管理连接对象，这些连接对象资源只有在连接断开时才会释放。如果长连接累计很多，将导致 MySQL 服务占用内存太大，有可能会被系统强制杀掉，这样会发生 MySQL 服务异常重启的现象。

有两种解决方式。

第一种，**定期断开长连接**。既然断开连接后就会释放连接占用的内存资源，那么我们可以定期断开长连接。

第二种，**客户端主动重置连接**。MySQL 5.7 版本实现了 `mysql_reset_connection()` 函数的接口，注意这是接口函数不是命令，那么当客户端执行了一个很大的操作后，在代码里调用 mysql_reset_connection 函数来重置连接，达到释放内存的效果。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。



# MySQL规范和优化

## 使用规范

### 表规范

**1:N 关系的设计**

在从表（`N`的这一方）创建一个字段，以字段作为外键指向主表（`1`的这一方）的主键。如学生表是多（`N`）的一方，会有个字段`class_id`保存班级表的主键。



**N:N关系的设计**

通过增加第三张表，把`N:N`修改为两个 `1:N`。



### 命名规范

- 表名、字段名必须使用小写字母或者数字并用下划线分割，禁止使用数字开头，禁止使用拼音，并且一般不使用英文缩写。
- 主键索引名为`pk_字段名`；唯一索引名为`uk_字段名`；普通索引名则为`idx_字段名`。
- 临时库表必须以tmp_为前缀并以日期为后缀，备份表必须以bak_为前缀并以日期(时间戳)为后缀
- 所有数据库对象名称禁止使用MySQL保留关键字
- 数据库对象的命名要能做到见名识意，并且最好不要超过32个字符
- 所有存储相同数据的列名和类型必须一致



### 基本设计规范

**所有表必须使用Innodb存储引擎**

```
没有特殊要求（即Innodb无法满足的功能如：列存储，存储空间数据等）的情况下，所有表必须使用Innodb存储引擎（mysql5.5之前默认使用Myisam，5.6以后默认的为Innodb）
Innodb 支持事务，支持行级锁，更好的恢复性，高并发下性能更好
```



**数据库和表的字符集统一使用UTF8**

```
兼容性更好，统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效，如果数据库中有存储emoji表情的需要，字符集需要采用utf8mb4字符集
```



**所有表和字段都需要添加注释**

```
使用comment从句添加表和列的备注
从一开始就进行数据字典的维护
```



**尽量控制单表数据量的大小，建议控制在500万以内**

500万并不是Mysql数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题
可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小



**谨慎使用Mysql分区表**

```
分区表在物理上表现为多个文件，在逻辑上表现为一个表
谨慎选择分区键，跨分区查询效率可能更低
建议采用物理分表的方式管理大数据
```



**尽量做到冷热数据分离，减小表的宽度**

```
Mysql限制每个表最多存储4096列，并且每一行数据的大小不能超过65535字节

减少磁盘IO,保证热数据的内存缓存命中率（表越宽，把表装载进内存缓冲池时所占用的内存也就越大,也会消耗更多的IO）
更有效的利用缓存，避免读入无用的冷数据
经常一起使用的列放到一个表中（避免更多的关联操作）
```



**禁止在表中建立预留字段**

```
预留字段的命名很难做到见名识义
预留字段无法确认存储的数据类型，所以无法选择合适的类型
对预留字段类型的修改，会对表进行锁定
```



**禁止在数据库中存储图片，文件等大的二进制数据**

```
通常文件很大，会短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机IO操作，文件很大时，IO操作很耗时
通常存储于文件服务器，数据库只存储文件地址信息
```

**禁止在线上做数据库压力测试**

**禁止从开发环境，测试环境直接连接生成环境数据库**



### 字段设计规范

- 尽可能选择存储空间小的字段类型，就好像数字类型的，从`tinyint、smallint、int、bigint`从左往右开始选择
- 小数类型如金额，则选择 `decimal`，禁止使用 `float` 和 `double`。
- 如果存储的字符串长度几乎相等，使用 `char` 定长字符串类型。
- `varchar`是可变长字符串，不预先分配存储空间，长度不要超过`5000`。
- 如果存储的值太大，建议字段类型修改为`text`，同时抽出单独一张表，用主键与之对应。
- 同一表中，所有`varchar`字段的长度加起来，不能大于`65535`. 如果有这样的需求，请使用`TEXT/LONGTEXT `类型。
- 选择合适的字段长度，一般是2的幂；



**优先选择符合存储需要的最小的数据类型**

```
原因是：列的字段越大，建立索引时所需要的空间也就越大，这样一页中所能存储的索引节点的数量也就越少也越少，在遍历时所需要的IO次数也就越多，
索引的性能也就越差
方法：
```

- 将字符串转换成数字类型存储，如：将IP地址转换成整形数据

mysql提供了两个方法来处理ip地址

inet_aton 把ip转为无符号整型(4-8位)
inet_ntoa 把整型的ip转为地址

插入数据前，先用inet_aton把ip地址转为整型，可以节省空间
显示数据时，使用inet_ntoa把整型的ip地址转为地址显示即可。

- 对于非负型的数据（如自增ID、整型IP）来说，要优先使用无符号整型来存储

因为：无符号相对于有符号可以多出一倍的存储空间
SIGNED INT -2147483648~2147483647
UNSIGNED INT 0~4294967295

VARCHAR(N)中的N代表的是字符数，而不是字节数
使用UTF8存储255个汉字 Varchar(255)=765个字节

过大的长度会消耗更多的内存



**避免使用TEXT、BLOB数据类型，最常见的TEXT类型可以存储64k的数据**

- 建议把BLOB或是TEXT列分离到单独的扩展表中

Mysql内存临时表不支持TEXT、BLOB这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行
而且对于这种数据，Mysql还是要进行二次查询，会使sql性能变得很差，但是不是说一定不能使用这样的数据类型

如果一定要使用，建议把BLOB或是TEXT列分离到单独的扩展表中，查询时一定不要使用select * 而只需要取出必要的列，不需要TEXT列的数据时不要对该列进行查询

- TEXT或BLOB类型只能使用前缀索引

因为MySQL对索引字段长度是有限制的，所以TEXT类型只能使用前缀索引，并且TEXT列上是不能有默认值的



**避免使用ENUM类型**

修改ENUM值需要使用ALTER语句，ENUM类型的ORDER BY操作效率低，需要额外操作，禁止使用数值作为ENUM的枚举值。



**尽可能把所有列定义为NOT NULL**

索引NULL列需要额外的空间来保存，所以要占用更多的空间，进行比较和计算时要对NULL值做特别的处理。

- 首先，` NOT NULL` 可以防止出现空指针问题。
- 其次，`NULL`值存储也需要额外的空间的，它也会导致比较运算更为复杂，使优化器难以优化SQL。
- `NULL`值有可能会导致索引失效
- 如果将字段默认设置成一个空字符串或常量值并没有什么不同，且都不会影响到应用逻辑， 那就可以将这个字段设置为`NOT NULL`。



**使用TIMESTAMP（4个字节）或DATETIME类型（8个字节）存储时间**

TIMESTAMP 存储的时间范围 1970-01-01 00:00:01 ~ 2038-01-19-03:14:07，TIMESTAMP 占用4字节和INT相同，但比INT可读性高，超出TIMESTAMP取值范围的使用DATETIME类型存储。

经常会有人用字符串存储日期型的数据（不正确的做法）

- 缺点1：无法用日期函数进行计算和比较

- 缺点2：用字符串存储日期要占用更多的空间



**同财务相关的金额类数据必须使用decimal类型**

- 非精准浮点：float,double
- 精准浮点：decimal

Decimal类型为精准浮点数，在计算时不会丢失精度

占用空间由定义的宽度决定，每4个字节可以存储9位数字，并且小数点要占用一个字节

可用于存储比bigint更大的整型数据



**添加通用字段**

表必备一般来说，或具备这几个字段：

- id：主键，一个表必须得有主键，必须
- create_time：创建时间，必须
- modifed_time/update_time: 修改时间，必须，更新记录时，需要更新它
- version : 数据记录的版本号，用于乐观锁，非必须
- remark ：数据记录备注，非必须
- modified_by :修改人，非必须
- creator ：创建人，非必须



**一张表的字段不宜过多**

如果一张表的字段过多，表中保存的数据可能就会很大，查询效率就会很低。如果业务需求，实在需要很多字段，可以把一张大的表，拆成多张小的表，它们的主键相同即可。当表的字段数非常多时，可以将表分成两张表，一张作为条件查询表，一张作为详细内容表 (主要是为了性能考虑)。



**不要创建外键关联**

- 使用外键存在性能问题、并发死锁问题、使用起来不方便等等。每次做`DELETE`或者`UPDATE`都必须考虑外键约束，会导致开发的时候很难受,测试数据造数据也不方便。
- 还有一个场景不能使用外键，就是分库分表。



### 索引设计规范

**限制每张表上的索引数量，建议单张表索引不超过5个**

```
索引并不是越多越好！索引可以提高效率同样可以降低效率

索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率

因为mysql优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个
索引都可以用于查询，就会增加mysql优化器生成执行计划的时间，同样会降低查询性能 
```



**禁止给表中的每一列都建立单独的索引**

```
5.6版本之前，一个sql只能使用到一个表中的一个索引，5.6以后，虽然有了合并索引的优化方式，但是还是远远没有使用一个联合索引的查询方式好
```



**每个Innodb表必须有个主键**

```
Innodb是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的
每个表都可以有多个索引，但是表的存储顺序只能有一种
Innodb是按照主键索引的顺序来组织表的

不要使用更新频繁的列作为主键，不适用多列主键（相当于联合索引）
不要使用UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长）
主键建议使用自增ID值
```



**常见索引列建议**

出现在SELECT、UPDATE、DELETE语句的WHERE从句中的列；包含在ORDER BY、GROUP BY、DISTINCT中的字段。并不要将符合1和2中的字段的列都建立一个索引， 通常将1、2中的字段建立联合索引效果更好。多表join的关联列。



**如何选择索引列的顺序**

建立索引的目的是：希望通过索引进行数据查找，减少随机IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少

区分度最高的放在联合索引的最左侧（区分度=列中不同值的数量/列的总行数）

尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO性能也就越好）

使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）



**避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间）**

重复索引示例：primary key(id)、index(id)、unique index(id)

冗余索引示例：index(a,b,c)、index(a,b)、index(a)



**对于频繁的查询优先考虑使用覆盖索引**

覆盖索引：就是包含了所有查询字段(where,select,ordery by,group by包含的字段)的索引

覆盖索引的好处:

- 避免Innodb表进行索引的二次查询

Innodb是以聚集索引的顺序来存储的，对于Innodb来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了IO操作，提升了查询效率。

- 可以把随机IO变成顺序IO加快查询效率

由于覆盖索引是按键值的顺序存储的，对于IO密集型的范围查找来说，对比随机从磁盘读取每一行的数据IO要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的IO转变成索引查找的顺序IO。



### 索引SET规范

**尽量避免使用外键约束**

不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引，外键可用于保证数据的参照完整性，但建议在业务端实现。外键会影响父表和子表的写操作从而降低性能。



### SQL开发规范

**建议使用预编译语句进行数据库操作**

```
预编译语句可以重复使用这些计划，减少SQL编译所需要的时间，还可以解决动态SQL所带来的SQL注入的问题
只传参数，比传递SQL语句更高效
相同语句可以一次解析，多次使用，提高处理效率
```



**避免数据类型的隐式转换**

```
隐式转换会导致索引失效
如:  select name,phone from customer where id = '111';
```



**充分利用表上已经存在的索引**

- 避免使用双%号的查询条件。

如 a like '%123%'，（如果无前置%,只有后置%，是可以用到列上的索引的）



- 一个SQL只能利用到复合索引中的一列进行范围查询

```
如 有 a,b,c列的联合索引，在查询条件中有a列的范围查询，则在b,c列上的索引将不会被用到，
在定义联合索引时，如果a列要用到范围查找的话，就要把a列放到联合索引的右侧
```



- 使用left join 或 not exists 来优化not in 操作

```
因为not in 也通常会使用索引失效
```



**数据库设计时，应该要对以后扩展进行考虑**

**程序连接不同的数据库使用不同的账号，禁止跨库查询**

```
为数据库迁移和分库分表留出余地
降低业务耦合度
避免权限过大而产生的安全风险
```



**禁止使用SELECT * 必须使用SELECT <字段列表> 查询**

```
    消耗更多的CPU和IO以网络带宽资源
    无法使用覆盖索引
    可减少表结构变更带来的影响
```



**禁止使用不含字段列表的INSERT语句**

```
如： insert into values ('a','b','c');
应使用 insert into t(c1,c2,c3) values ('a','b','c');
```



**避免使用子查询，可以把子查询优化为join操作**

```
通常子查询在in子句中，且子查询中为简单SQL(不包含union、group by、order by、limit从句)时,才可以把子查询转化为关联查询进行优化

子查询性能差的原因：

 子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响
 特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大
 由于子查询会产生大量的临时表也没有索引，所以会消耗过多的CPU和IO资源，产生大量的慢查询
```



**避免使用JOIN关联太多的表**

```
对于Mysql来说，是存在关联缓存的，缓存的大小可以由join_buffer_size参数进行设置
在Mysql中，对于同一个SQL多关联（join）一个表，就会多分配一个关联缓存，如果在一个SQL中关联的表越多，
所占用的内存也就越大

如果程序中大量的使用了多表关联的操作，同时join_buffer_size设置的也不合理的情况下，就容易造成服务器内存溢出的情况，
就会影响到服务器数据库性能的稳定性

同时对于关联操作来说，会产生临时表操作，影响查询效率
Mysql最多允许关联61个表，建议不超过5个
```



**减少同数据库的交互次数**

```
数据库更适合处理批量操作
合并多个相同的操作到一起，可以提高处理效率
```



**对应同一列进行or判断时，使用in代替or**

```
in 的值不要超过500个
in 操作可以更有效的利用索引，or大多数情况下很少能利用到索引
```



**禁止使用order by rand() 进行随机排序**

```
会把表中所有符合条件的数据装载到内存中，然后在内存中对所有数据根据随机生成的值进行排序，并且可能会对每一行都生成一个随机值，如果满足条件的数据集非常大，
就会消耗大量的CPU和IO及内存资源
推荐在程序中获取一个随机值，然后从数据库中获取数据的方式
```



**WHERE从句中禁止对列进行函数转换和计算**

```
对列进行函数转换或计算时会导致无法使用索引

不推荐：
where date(create_time)='20190101'
推荐：
where create_time >= '20190101' and create_time < '20190102'
```



**在明显不会有重复值时使用UNION ALL 而不是UNION**

```
UNION 会把两个结果集的所有数据放到临时表中后再进行去重操作
UNION ALL 不会再对结果集进行去重操作
```



**拆分复杂的大SQL为多个小SQL**

```
大SQL:逻辑上比较复杂，需要占用大量CPU进行计算的SQL
MySQL 一个SQL只能使用一个CPU进行计算
SQL拆分后可以通过并行执行来提高处理效率
```



**如果知道查询结果只有一条或者只要最大/最小一条记录，建议用limit 1**

- 加上limit 1后,只要找到了对应的一条记录,就不会继续向下扫描了,效率将会大大提高。
- 当然，如果name是唯一索引的话，是不必要加上limit 1了，因为limit的存在主要就是为了防止全表扫描，从而提高性能,如果一个语句本身可以预知不用全表扫描，有没有limit ，性能的差别并不大。



**优化limit分页**

当偏移量最大的时候，查询效率就会越低，因为Mysql并非是跳过偏移量直接去取后面的数据，而是先把偏移量+要取的条数，然后再把前面偏移量这一段的数据抛弃掉再返回的。

```sql
//方案一 ：返回上次查询的最大记录(偏移量)
select id，name from employee where id>10000 limit 10.

//方案二：orderby + 索引
select id，name from employee order by id limit 10000，10

//方案三：在业务允许的情况下限制页数：
```



- 如果使用优化方案一，返回上次最大查询记录（偏移量），这样可以跳过偏移量，效率提升不少。
- 方案二使用order by+索引，也是可以提高查询效率的。
- 方案三的话，建议跟业务讨论，有没有必要查这么后的分页啦。因为绝大多数用户都不会往后翻太多页。



**使用where条件限定要查询的数据，避免返回多余的行**

- 需要什么数据，就去查什么数据，避免返回不必要的数据，节省开销。



**Inner join 、left join、right join，优先使用Inner join，如果是left join，左边表结果尽量小**

Inner join 内连接，在两张表进行连接查询时，只保留两张表中完全匹配的结果集；left join 在两张表进行连接查询时，会返回左表所有的行，即使在右表中没有匹配的记录；right join 在两张表进行连接查询时，会返回右表所有的行，即使在左表中没有匹配的记录。



- 如果inner join是等值连接，或许返回的行数比较少，所以性能相对会好一点。
- 同理，使用了左连接，左边表数据结果尽量小，条件尽量放到左边处理，意味着返回的行数可能比较少。



### 操作行为规范

**超100万行的批量写（UPDATE、DELETE、INSERT）操作，要分批多次进行操作**

- 大批量操作可能会造成严重的主从延迟

主从环境中,大批量操作可能会造成严重的主从延迟，大批量的写操作一般都需要执行一定长的时间，
而只有当主库上执行完成后，才会在其他从库上执行，所以会造成主库与从库长时间的延迟情况

- binlog日志为row格式时会产生大量的日志

大批量写操作会产生大量日志，特别是对于row格式二进制数据而言，由于在row格式中会记录每一行数据的修改，我们一次修改的数据越多，
产生的日志量也就会越多，日志的传输和恢复所需要的时间也就越长，这也是造成主从延迟的一个原因

- 避免产生大事务操作

大批量修改数据，一定是在一个事务中进行的，这就会造成表中大批量数据进行锁定，从而导致大量的阻塞，阻塞会对MySQL的性能产生非常大的影响
特别是长时间的阻塞会占满所有数据库的可用连接，这会使生产环境中的其他应用无法连接到数据库，因此一定要注意大批量写操作要进行分批



**对于大表使用pt-online-schema-change修改表结构**

1. 避免大表修改产生的主从延迟
2. 避免在对表字段进行修改时进行锁表

对大表数据结构的修改一定要谨慎，会造成严重的锁表操作，尤其是生产环境，是不能容忍的

pt-online-schema-change它会首先建立一个与原表结构相同的新表，并且在新表上进行表结构的修改，然后再把原表中的数据复制到新表中，并在原表中增加一些触发器。把原表中新增的数据也复制到新表中，在行所有数据复制完成之后，把新表命名成原表，并把原来的表删除掉，把原来一个DDL操作，分解成多个小的批次进行。



**禁止为程序使用的账号赋予super权限**

```
当达到最大连接数限制时，还运行1个有super权限的用户连接
super权限只能留给DBA处理问题的账号使用
```



**对于程序连接数据库账号，遵循权限最小原则**

```
程序使用数据库账号只能在一个DB下使用，不准跨库
程序使用的账号原则上不准有drop权限
```



**慎用distinct关键字**

distinct 关键字一般用来过滤重复记录，以返回不重复的记录。在查询一个字段或者很少字段的情况下使用时，给查询带来优化效果。但是在字段很多的时候使用，却会大大降低查询效率。

带distinct的语句cpu时间和占用时间都高于不带distinct的语句。因为当查询很多字段时，如果使用distinct，数据库引擎就会对数据进行比较，过滤掉重复数据，然而这个比较，过滤的过程会占用系统资源，cpu时间。



**where子句中考虑使用默认值代替null。**

并不是说使用了is null 或者 is not null 就会不走索引了，这个跟mysql版本以及查询成本都有关。

如果把null值，换成默认值，很多时候让走索引成为可能，同时，表达意思会相对清晰一点。

如果mysql优化器发现，走索引比不走索引成本还要高，肯定会放弃索引，这些条件`！=，>is null，is not null`经常被认为让索引失效，其实是因为一般情况下，查询的成本高，优化器自动放弃的。



**exist & in的合理利用**

选择最外层循环小的，也就是，如果**B的数据量小于A，适合使用in，如果B的数据量大于A，即适合选择exist**。



## 使用优化

### 服务器优化

当服务器的内存够多时，配制线程数量 = 最大连接数+5，这样能发挥最大的效率；否则使用配制线程数量<最大连接数启用SQL SERVER的线程池来解决，如果还是数量 = 最大连接数+5，严重的损害服务器的性能；



### 建表优化

- 避免在创建表时NULL是默认值，然后在where子句中对字段进行null值判断，应该使用NOT NULL，或者用0作为默认值；
- 使用数字型字段，若只含数值信息的字段不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销；
- 创建表时字段类型在满足需求的情况下越小越好；使用varchar/nvarchar代替char/nchar，变长字段存储空间小，可以节省存储空间，而且在一个相对较小的字段内查询效率要高些；
- 将需要查询的结果预先计算好放在表中，查询的时候再Select



### 查询优化

- 避免select *，将需要查找的字段列出来；
- 尽量做单表查询，避免任何方式的多表查询；进行多表查询时可将连接（join）查询来代替子查询；
- sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库；
- 不用函数和触发器，在应用程序实现；
- 使用同类型进行比较，比如用'123'和'123'比，123和123比；
- OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内；
- 对于连续数值，使用BETWEEN不用IN；
- 列表数据不要拿全表，要使用LIMIT来分页限定，每页数量也不要太大；
- 可以通过将不需要的记录在GROUP BY之前过滤掉来提高GROUP BY语句的效率；
- 当只要一行数据时使用LIMIT 1；
- 不做列运算：SELECT id WHERE age + 1 = 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边；
- 应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描；
- Like左模糊查询也会导致全表扫描；
- 尽量避免在WHERE子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描；
- 应尽量避免在where子句中使用or来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，可以使用UNION合并查询：



#### **利用覆盖索引**

InnoDB使用非主键索引查询数据时会回表，但是如果索引的叶节点中已经包含要查询的字段，那它没有必要再回表查询了，这就叫覆盖索引



#### **低版本避免使用or查询**

在 MySQL 5.0 之前的版本要尽量避免使用 or 查询，可以使用 union 或者子查询来替代，因为早期的 MySQL 版本使用 or 查询可能会导致索引失效，高版本引入了索引合并，解决了这个问题。



#### **避免使用 != 或者 <> 操作符**

SQL中，不等于操作符会导致查询引擎放弃查询索引，引起全表扫描，即使比较的字段上有索引

解决方法：通过把不等于操作符改成or，可以使用索引，避免全表扫描



#### **适当使用前缀索引**

适当地使用前缀所云，可以降低索引的空间占用，提高索引的查询效率。

比如，邮箱的后缀都是固定的“`@xxx.com`”，那么类似这种后面几位为固定值的字段就非常适合定义为前缀索引

需要注意的是，前缀索引也存在缺点，MySQL无法利用前缀索引做order by和group by 操作，也无法作为覆盖索引



#### **避免列上函数运算**

要避免在列字段上进行算术运算或其他表达式运算，否则可能会导致存储引擎无法正确使用索引，从而影响了查询的效率



#### **正确使用联合索引**

使用联合索引的时候，注意最左匹配原则。



#### 禁止3表JOIN查询

- MySQL的SQL优化器在针对超过3张表的关联查询时，NLJ多级嵌套性能差。
- 多张表关联的数据迁移时改造困难。



##### 解决方式

- 单表查出结果后作为条件in查询关联的表。但此时只适用于数据量小且要是INNER JOIN的情况。
- 通过反范式表来查询，反范式表指的是冗余所有的需要的字段到一张大表中。
- 通过数据仓库来获取数据。
- 通过倒排表来获取数据。



#### **优化子查询**

尽量使用 Join 语句来替代子查询，因为子查询是嵌套查询，而嵌套查询会新创建一张临时表，而临时表的创建与销毁会占用一定的系统资源以及花费一定的时间，同时对于返回结果集比较大的子查询，其对查询性能的影响更大



#### **小表驱动大表**

关联查询的时候要拿小表去驱动大表，因为关联的时候，MySQL内部会遍历驱动表，再去连接被驱动表。

比如left join，左表就是驱动表，A表小于B表，建立连接的次数就少，查询速度就被加快了。



#### **适当增加冗余字段**

增加冗余字段可以减少大量的连表查询，因为多张表的连表查询性能很低，所有可以适当的增加冗余字段，以减少多张表的关联查询，这是以空间换时间的优化策略。



#### **利用索引扫描做排序**

MySQL有两种方式生成有序结果：其一是对结果集进行排序的操作，其二是按照索引顺序扫描得出的结果自然是有序的

但是如果索引不能覆盖查询所需列，就不得不每扫描一条记录回表查询一次，这个读操作是随机IO，通常会比顺序全表扫描还慢

因此，在设计索引时，尽可能使用同一个索引既满足排序又用于查找行

只有当索引的列顺序和ORDER BY子句的顺序完全一致，并且所有列的排序方向都一样时，才能够使用索引来对结果做排序



#### **条件下推**

MySQL处理union的策略是先创建临时表，然后将各个查询结果填充到临时表中最后再来做查询，很多优化策略在union查询中都会失效，因为它无法利用索引

最好手工将where、limit等子句下推到union的各个子查询中，以便优化器可以充分利用这些条件进行优化

此外，除非确实需要服务器去重，一定要使用union all，如果不加all关键字，MySQL会给临时表加上distinct选项，这会导致对整个临时表做唯一性检查，代价很高。



### 更新优化

- 当有一批处理的插入或更新时，用批量插入或批量更新，绝不会一条条记录的去更新



### 索引优化

- 索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描；
- 值分布很稀少的字段不适合建索引，例如"sex"；
- 尽量不用UNIQUE，由程序保证约束；
- 索引的创建要与应用结合考虑，建议大的OLTP表不要超过6个索引；
- 字符字段只建前缀索引
- 字符字段最好不要做主键
- 使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引
- 频繁进行数据操作的表，不要建立太多的索引； 



### 其它优化

- 避免对大表查询时进行table scan，必要时考虑新建索引；

​	

### 大表优化

- 限定数据的范围

​	务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；



- 读/写分离

经典的数据库拆分方案，主库负责写，从库负责读；



- 垂直拆分和水平拆分



### 表数据优化

#### optimize table

对于经常修改的表，容易产生碎片，使在查询数据库时必须读取更多的磁盘块，降低查询性能。具有可变长的表都存在磁盘碎片问题，这个问题对blob数据类型更为突出，因为其尺寸变化非常大。

可以通过使用optimize table来整理碎片，保证数据库性能不下降，优化那些受碎片影响的数据表。optimize table可以用于MyISAM和BDB类型的数据表。实际上任何碎片整理方法都是用mysqldump来转存数据表，然后使用转存后的文件并重新建数据表；



## 系统调优

可以使用下面几个工具来做基准测试：

- [sysbench](https://link.segmentfault.com/?enc=K4C%2FJWzWGetm0SjR%2FXLViw%3D%3D.CvVtBn6W0WBRTP6yYQBcyN2ffg%2B%2FU04yb6vKLmbN6FMUbvgKPznfOeBp%2FMEIay3m)：一个模块化，跨平台以及多线程的性能测试工具
- [iibench-mysql](https://link.segmentfault.com/?enc=WYWyQrcDLK9pjdTz9IVu6A%3D%3D.vNPyeW%2BgGlu8TwHhX%2F6p9UmViYFPlGNu5bgzRLmdiI%2FiKtaQ31S2lG0ash%2Fuf1%2Bu)：基于 Java 的 MySQL/Percona/MariaDB 索引进行插入性能测试工具
- [tpcc-mysql](https://link.segmentfault.com/?enc=3udMCZz5B61kAvb%2FA9znuw%3D%3D.TftoccNADM%2FxGy6ndsIsFteGtzs7ruXuBJ1gA%2FQwWV885ZqP14HjGjVyWCLd90i8)：Percona开发的TPC-C测试工具

具体的调优参数内容较多，具体可参考官方文档，这里介绍一些比较重要的参数：

- back_log：back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果MySql的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。可以从默认的50升至500
- wait_timeout：数据库连接闲置时间，闲置连接会占用内存资源。可以从默认的8小时减到半小时
- max_user_connection: 最大连接数，默认为0无上限，最好设一个合理上限
- thread_concurrency：并发线程数，设为CPU核数的两倍
- skip_name_resolve：禁止对外部连接进行DNS解析，消除DNS解析时间，但需要所有远程主机用IP访问
- key_buffer_size：索引块的缓存大小，增加会提升索引处理速度，对MyISAM表性能影响最大。对于内存4G左右，可设为256M或384M，通过查询`show status like 'key_read%'`，保证`key_reads / key_read_requests`在0.1%以下最好
- innodb_buffer_pool_size：缓存数据块和索引块，对InnoDB表性能影响最大。通过查询`show status like 'Innodb_buffer_pool_read%'`，保证` (Innodb_buffer_pool_read_requests – Innodb_buffer_pool_reads) / Innodb_buffer_pool_read_requests`越高越好
- innodb_additional_mem_pool_size：InnoDB存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小，当数据库对象非常多的时候，适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率，当过小的时候，MySQL会记录Warning信息到数据库的错误日志中，这时就需要该调整这个参数大小
- innodb_log_buffer_size：InnoDB存储引擎的事务日志所使用的缓冲区，一般来说不建议超过32MB
- query_cache_size：缓存MySQL中的ResultSet，也就是一条SQL语句执行的结果集，所以仅仅只能针对select语句。当某个表的数据有任何任何变化，都会导致所有引用了该表的select语句在Query Cache中的缓存数据失效。所以，当我们的数据变化非常频繁的情况下，使用Query Cache可能会得不偿失。根据命中率`(Qcache_hits/(Qcache_hits+Qcache_inserts)*100))`进行调整，一般不建议太大，256MB可能已经差不多了，大型的配置型静态数据可适当调大.
	可以通过命令`show status like 'Qcache_%'`查看目前系统Query catch使用大小
- read_buffer_size：MySql读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql会为它分配一段内存缓冲区。如果对表的顺序扫描请求非常频繁，可以通过增加该变量值以及内存缓冲区大小提高其性能
- sort_buffer_size：MySql执行排序使用的缓冲大小。如果想要增加`ORDER BY`的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。如果不能，可以尝试增加sort_buffer_size变量的大小
- read_rnd_buffer_size：MySql的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。
- record_buffer：每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，可能想要增加该值
- thread_cache_size：保存当前没有与连接关联但是准备为后面新的连接服务的线程，可以快速响应连接的线程请求而无需创建新的
- table_cache：类似于thread_cache_size，但用来缓存表文件，对InnoDB效果不大，主要用于MyISAM



## MySQL优化

SQL优化主要分4个方向：`SQL语句跟索引`、`表结构`、`系统配置`、`硬件`。

总优化思路就是**最大化利用索引**、**尽可能避免全表扫描**、**减少无效数据的查询**：

1、减少数据访问：设置合理的字段类型，启用压缩，通过索引访问等减少磁盘 IO。

2、返回更少的数据：只返回需要的字段和数据分页处理，减少磁盘 IO 及网络 IO。

3、减少交互次数：批量 DML 操作，函数存储等减少数据连接次数。

4、减少服务器 CPU 开销：尽量减少数据库排序操作以及全表查询，减少 CPU 内存占用 。

5、分表分区：使用表分区，可以增加并行操作，更大限度利用 CPU 资源。



### SQL语句和索引

1、合理建立覆盖索引：可以有效减少回表。

2、union，or，in都能命中索引，建议使用in 

3、负向条件(!=、<>、not in、not exists、not like 等) 索引不会使用索引，建议用in。

4、在列上进行运算或使用函数会使索引失效，从而进行全表扫描 

5、小心隐式类型转换，原字符串用整型会触发CAST函数导致索引失效。原int用字符串则会走索引。

6、不建议使用%前缀模糊查询。

7、多表关联查询时，小表在前，大表在后。在 MySQL 中，执行 from 后的表关联查询是从左往右执行的(Oracle 相反)，第一张表会涉及到全表扫描。

8、调整 Where 字句中的连接顺序，MySQL 采用从左往右，自上而下的顺序解析 where 子句。根据这个原理，应将过滤数据多的条件往前放，最快速度缩小结果集。



### 表结构

1、尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED 。

2、VARCHAR的长度只分配真正需要的空间 。

3、尽量使用TIMESTAMP而非DATETIME 。

4、单表不要有太多字段，建议在20以内。

5、避免使用NULL字段，设置默认值。



### 系统配置

#### 读写分离

只在主服务器上写，只在从服务器上读。对应到数据库集群一般都是一主一从、一主多从。业务服务器把需要写的操作都写到主数据库中，读的操作都去从库查询。主库会同步数据到从库保证数据的一致性。一般 读写分离 的实现方式有两种：代码封装跟数据库中间件。



#### 分库分表

分库分表：分库分表分为垂直和水平两个方式，一般是先垂直后水平。

1、垂直分库：将应用分为若干模块，比如订单模块、用户模块、商品模块、支付模块等等。其实就是微服务的理念。

2、垂直分表：一般将不常用字段跟数据较大的字段做拆分。

3、水平分表：根据场景选择什么字段作分表字段，比如淘宝日订单1000万，用userId作分表字段，数据查询支持到最近6个月的订单，超过6个月的做归档处理，那么6个月的数据量就是18亿，分1024张表，每个表存200W数据，hash(userId)%100找到对应表格。

4、ID生成器：分布式ID 需要跨库全局唯一方便查询存储-检索数据，确保唯一性跟数字递增性。



目前主要流行的分库分表工具 就是`Mycat`和`sharding-sphere`。



## 使用优化

### 分库分表

随着业务的增长，如果集群中的节点数量过多，最终会达到数据库的连接限制，导致集群中的节点数量受限于数据库连接数，集群节点无法持续增加和扩容，无法应对业务流量的持续增长；这也是蚂蚁做 LDC 架构的其中原因之一，在业务层做水平拆分和扩展，使得每个单元的节点只访问当前节点对应的数据库。



### 避免大量的表JOIN

阿里编码规约中超过三个表禁止 JOIN，因为三个表进行笛卡尔积计算会出现操作复杂度呈几何数增长，多个表 JOIN 时要确保被关联的字段有索引。

如果为了业务上某些数据的级联，可以适当根据主键在内存中做嵌套的查询和计算，操作非常频繁的流水表建议对部分字段做冗余，以空间复杂度换取时间复杂度。



### 减少业务流水表大量耗时计算

业务记录有时候会做一些 count 操作，如果对时效性要求不高的统计和计算，建议定时任务在业务低峰期做好计算，然后将计算结果保存在缓存。

涉及到多个表 JOIN 的建议采用离线表进行聚合计算，然后再将计算结果回流到线上表进行展示。



### 数据过期策略

一张表的数据量太大的情况下，如果不按照索引和日期进行部分扫描而出现全表扫描的情况，对 DB 的查询性能是非常有影响的，建议合理的设计数据过期策略，历史数据定期放入 history 表，或者备份到离线表中，减少线上大量数据的存储。



### 合理使用内存

众所周知，关系型数据库 DB 查询底层是磁盘存储，计算速度低于内存缓存，缓存 DB 与业务系统连接有一定的调用耗时，速度低于本地内存；但是从存储量来看，内存存储数据容量低于缓存，长期持久化的数据建议放 DB 存在磁盘中，设计过程中考虑好成本和查询性能的平衡。



# Production Scene
## 使用场景

### 慢SQL

#### 定位

- **慢查询日志**：开启MySQL的慢查询日志，再通过一些工具比如mysqldumpslow去分析对应的慢查询日志，当然现在一般的云厂商都提供了可视化的平台。
- **服务监控**：可以在业务的基建中加入对慢SQL的监控，常见的方案有字节码插桩、连接池扩展、ORM框架过程，对服务运行中的慢SQL进行监控和告警。



#### 排查

慢SQL排查主要从一下几个角度来进行排查：

- 索引使用情况
- 数据库连接数过小
- 应用侧连接数过小
- buffer pool太小



### 表廋身

MySQL执行`delete`命令其实只是把记录的位置，或者数据页标记为了`可复用`，但磁盘文件的大小是不会变的。通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是`空洞`。插入时候引发分裂同样会产生空洞。



**重建表思路**：

1、新建一个跟A表结构相同的表B 

2、按照主键ID将A数据一行行读取同步到表B 

3、用表B替换表A实现效果上的瘦身。



### 隐藏敏感信息

#### 隐藏姓名

```sql
SELECT `name` AS `before_encrypt`,
	CASE CHAR_LENGTH(`name`)
	WHEN 2 THEN CONCAT('*',SUBSTRING(`name`, 2, 1))
	WHEN 3 THEN CONCAT(SUBSTRING(`name`, 1, 1),'*',SUBSTRING(`name`, -1, 1))
	ELSE CONCAT(SUBSTRING(`name`, 1, CHAR_LENGTH(`name`) - 2),'**')
	END AS `after_encrypt`
FROM `user`
```



#### 隐藏手机号

```sql
SELECT `mobile` AS `before_encrypt`, 
INSERT(`mobile`, CHAR_LENGTH(`mobile`) - 7, 4, '****') AS `after_encrypt`
FROM `user`
```



#### 隐藏身份证号

```sql
SELECT `id_card_no` AS `before_encrypt`, 
INSERT(`id_card_no`, 7, 8, '********') AS `after_encrypt`
FROM `user`
```



## 问题排查

### 慢SQL原因排查

大多数情况下很正常，偶尔很慢，则有如下原因

- 数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。

- 执行的时候，遇到锁，如表锁、行锁。可以用 **show processlist**这个命令来查看当前的状态。

这条 SQL 语句一直执行的很慢，则有如下原因。

- 没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。

- 数据库选错了索引，可以使用强制指定索引来解决。
