---
layout: post
title: 生产解决方案.md
categories: [cate1, cate2]
description: some word here
keywords: keyword1, keyword2
mermaid: false
sequence: false
flow: false
mathjax: false
mindmap: false
mindmap2: false
---
# System Optimize

## 优化类型

空间换时间：

- 索引
- 缓存



时间换空间

- 压缩



时间换时间

- **削峰填谷**
- 

## 索引

### 索引数据结构

- **哈希表（Hash Table）**：哈希表的原理可以类比银行办业务取号，给每个人一个号（计算出的Hash值），叫某个号直接对应了某个人，索引效率是最高的O(1)，消耗的存储空间也相对更大。K-V存储组件以及各种编程语言提供的Map/Dict等数据结构，多数底层实现是用的哈希表。
- **二叉搜索树（Binary Search Tree）**：有序存储的二叉树结构，在编程语言中广泛使用的**红黑树**属于二叉搜索树，确切的说是“不完全平衡的”二叉搜索树。从C++、Java的TreeSet、TreeMap，到Linux的CPU调度，都能看到红黑树的影子。Java的HashMap在发现某个Hash槽的链表长度大于8时也会将链表升级为红黑树，而相比于红黑树“更加平衡”的AVL树反而实际用的更少。
- **平衡多路搜索树（B-Tree）**：这里的B指的是Balance而不是Binary，二叉树在大量数据场景会导致查找深度很深，解决办法就是变成多叉树，MongoDB的索引用的就是B-Tree。
- **叶节点相连的平衡多路搜索树（B+ Tree）**：B+ Tree是B-Tree的变体，只有叶子节点存数据，叶子与相邻叶子相连，MySQL的索引用的就是B+树，Linux的一些文件系统也使用的B+树索引inode。其实B+树还有一种在枝桠上再加链表的变体：B*树，暂时没想到实际应用。
- **日志结构合并树（LSM Tree）**：Log Structured Merge Tree，简单理解就是像日志一样顺序写下去，多层多块的结构，上层写满压缩合并到下层。LSM Tree其实本身是为了优化写性能牺牲读性能的数据结构，并不能算是索引，但在大数据存储和一些NoSQL数据库中用的很广泛，因此这里也列进去了。
- **字典树（Trie Tree）**：又叫前缀树，从树根串到树叶就是数据本身，因此树根到枝桠就是前缀，枝桠下面的所有数据都是匹配该前缀的。这种结构能非常方便的做前缀查找或词频统计，典型的应用有：自动补全、URL路由。其变体基数树（Radix Tree）在Nginx的Geo模块处理子网掩码前缀用了；Redis的Stream、Cluster等功能的实现也用到了基数树（Redis中叫Rax）。
- **跳表（Skip List）**：是一种多层结构的有序链表，插入一个值时有一定概率“晋升”到上层形成间接的索引。跳表更适合大量并发写的场景，不存在红黑树的再平衡问题，Redis强大的ZSet底层数据结构就是哈希加跳表。
- **倒排索引（Inverted index）**：这样翻译不太直观，可以叫“关键词索引”，比如书籍末页列出的术语表就是倒排索引，标识出了每个术语出现在哪些页，这样我们要查某个术语在哪用的，从术语表一查，翻到所在的页数即可。倒排索引在全文索引存储中经常用到，比如ElasticSearch非常核心的机制就是倒排索引；Prometheus的时序数据库按标签查询也是在用倒排索引。



## 压缩

压缩的原理**消耗计算的时间，换一种更紧凑的编码方式来表示数据**。**对数据的压缩虽然消耗了时间来换取更小的空间存储，但更小的存储空间会在另一个维度如传输带来更大的时间收益**。本质上是**操作系统内核与网络设备处理负担 vs 压缩解压的CPU/GPU负担**。



### 无损压缩场景

- HTTP协议中Accept-Encoding添加Gzip/deflate，服务端对接受压缩的文本（JS/CSS/HTML）请求做压缩，大部分图片格式本身已经是压缩的无需压缩；
- HTTP2协议的头部HPACK压缩；
- JS/CSS文件的混淆和压缩（Uglify/Minify）；
- 一些RPC协议和消息队列传输的消息中，采用二进制编码和压缩（Gzip、Snappy、LZ4等等）；
- 缓存服务存过大的数据，通常也会事先压缩一下再存，取的时候解压；
- 一些大文件的存储，或者不常用的历史数据存储，采用更高压缩比的算法存储；
- JVM的对象指针压缩，JVM在32G以下的堆内存情况下默认开启“UseCompressedOops”，用4个byte就可以表示一个对象的指针，这也是JVM尽量不要把堆内存设置到32G以上的原因；
- MongoDB的二进制存储的BSON相对于纯文本的JSON也是一种压缩，或者说更紧凑的编码。但更紧凑的编码也意味着更差的可读性，这一点也是需要取舍的。纯文本的JSON比二进制编码要更占存储空间但却是REST API的主流，因为数据交换的场景下的可读性是非常重要的。



### 有损压缩场景

- 预览和缩略图，低速网络下视频降帧、降清晰度，都是对信息的有损压缩；
- 音视频等多媒体数据的**采样和编码**大多是有损的，比如MP3是利用傅里叶变换，有损地存储音频文件；jpeg等图片编码也是有损的。虽然有像WAV/PCM这类无损的音频编码方式，但多媒体数据的**采样本身就是有损的**，相当于只截取了真实世界的极小一部分数据；
- **散列化**，比如K-V存储时Key过长，先对Key执行一次“傻”系列（SHA-1、SHA-256）哈希算法变成固定长度的短Key。另外，散列化在文件和数据验证（MD5、CRC、HMAC）场景用的也非常多，无需耗费大量算力对比完整的数据。



### 极端压缩

**压缩的极端**——从根本上**减少数据或彻底删除**。



#### 减少数据场景

- JS打包过程“摇树”，去掉没有使用的文件、函数、变量；
- 开启HTTP/2和高版本的TLS，减少了Round Trip，节省了TCP连接，自带大量性能优化；
- 减少不必要的信息，比如Cookie的数量，去掉不必要的HTTP请求头；
- 更新采用增量更新，比如HTTP的PATCH，只传输变化的属性而不是整条数据；
- 缩短单行日志的长度、缩短URL、在具有可读性情况下用短的属性名等等；
- 使用位图和位操作，用风骚的**位操作最小化存取的数据**。典型的例子有：用Redis的位图来记录统计海量用户登录状态；布隆过滤器用位图排除不可能存在的数据；大量开关型的设置的存储等等。



#### 删除数据场景

- 删掉不用的数据；
- 删掉不用的索引；
- 删掉不该打的日志；
- 删掉不必要的通信代码，不去发不必要的HTTP、RPC请求或调用，轮询改发布订阅；
- **终极方案：砍掉整个功能**。



## 缓存

### 浏览器打开页面过程中的缓存

- 首先解析DNS时，浏览器一层DNS缓存、操作系统一层DNS缓存、DNS服务器链上层层缓存；
- 发送一个GET请求这篇文章，服务端很可能早已将其缓存在KV存储组件中了；
- 即使没有击中缓存，数据库服务器内存中也缓存了最近查询的数据；
- 即使没有击中数据库服务器的缓存，数据库从索引文件中读取，操作系统已经把热点文件的内容放置在Page Cache中了；
- 即使没有击中操作系统的文件缓存，直接读取文件，大部分固态硬盘或者磁盘本身也自带缓存；
- 数据取到之后服务器用模板引擎渲染出HTML，模板引擎早已解析好缓存在服务端内存中了；
- 历经数十毫秒之后，终于服务器返回了一个渲染后的HTML，浏览器端解析DOM树，发送请求来加载静态资源；
- 需要加载的静态资源可能因Cache-Control在浏览器本地磁盘和内存中已经缓存了；
- 即使本地缓存到期，也可能因Etag没变服务器告诉浏览器304 Not Modified继续缓存；
- 即使Etag变了，静态资源服务器也因其他用户访问过早已将文件缓存在内存中了；
- 加载的JS文件会丢到JS引擎执行，其中可能涉及的种种缓存就不再展开了；
- 整个过程中链条上涉及的**所有的计算机和网络设备**，执行的热点代码和数据很可能会载入CPU的多级高速缓存。



### 缓存失效和不一致

- 多线程并发编程需要用各种手段（比如Java中的synchronized volatile）防止并发更新数据，一部分原因就是防止线程**本地缓存的不一致**；
- 缓存失效衍生的问题还有：**缓存穿透、缓存击穿、缓存雪崩**。解决用不存在的Key来穿透攻击，需要用空值缓存或布隆过滤器；解决单个缓存过期后，瞬间被大量恶意查询击穿的问题需要做查询互斥；解决某个时间点大量缓存同时过期的雪崩问题需要添加随机TTL；
- 热点数据如果是**多级缓存**，在发生修改时需要清除或修改**各级缓存**，这些操作往往不是原子操作，又会涉及各种不一致问题。



### 池化

通常意义上的缓存外，**对象重用的池化技术**，也可以看作是一种**缓存的变体**。常见的诸如JVM，V8这类运行时的**常量池、数据库连接池、HTTP连接池、线程池、Golang的sync.Pool对象池**等等。在需要某个资源时从现有的池子里直接拿一个，稍作修改或直接用于另外的用途，池化重用也是性能优化常见手段。



## 预取

**预取**通常搭配缓存一起用，其原理是**在缓存空间换时间基础上**更进一步，再加上一次“**时间换时间**”，也就是：**用事先预取的耗时，换取第一次加载的时间**。猜测出以后的某个时间很有可能会用到某种数据时，把数据预先取到需要用的地方，能大幅度提升用户体验或服务端响应速度。



### 预取场景

- 视频或直播类网站，在播放前先缓冲一小段时间，就是预取数据。有的在播放时不仅预取这一条数据，甚至还会预测下一个要看的其他内容，提前把数据取到本地；
- **HTTP/2 Server Push**，在浏览器请求某个资源时，服务器顺带把其他相关的资源一起推回去，HTML/JS/CSS几乎同时到达浏览器端，相当于浏览器被动预取了资源；
- 一些客户端软件会用常驻进程的形式，提前预取数据或执行一些代码，这样可以极大提高第一次使用的打开速度；
- 服务端同样也会用一些预热机制，一方面**热点数据预取到内存提前形成多级缓存**；另一方面也是**对运行环境的预热**，载入CPU高速缓存、热点函数JIT编译成机器码等等；
- **热点资源提前预分配**到各个实例，比如：秒杀、售票的**库存性质的数据**；分布式**唯一ID**等等。



### 预取副作用

在软件代码中做预取/预热的副作用通常是启动慢一些、占用一些闲时的计算资源、可能取到的**不一定是后面需要的**。



## 削峰填谷

**削峰填谷**的原理也是“**时间换时间**”，**谷时换峰时**。削峰填谷与**预取**是反过来的：预取是事先花时间做，削峰填谷是事后花时间做。



### 使用场景

- 针对前端、客户端的**启动优化或首屏优化**：代码和数据等资源的**延时加载、分批加载、后台异步加载、或按需懒加载**等等。
- **背压控制** - **限流、节流、去抖**等等。一夫当关，万夫莫开，从**入口处削峰**，防止一些恶意重复请求以及请求过于频繁的爬虫，甚至是一些DDoS攻击。简单做法有网关层根据单个IP或用户用漏桶控制请求速率和上限；前端做按钮的节流去抖防止重复点击；网络层开启TCP SYN Cookie防止恶意的SYN洪水攻击等等。彻底杜绝爬虫、黑客手段的恶意洪水攻击是很难的，DDoS这类属于网络安全范畴了。
- 针对正常的业务请求洪峰，**用消息队列暂存再异步化处理**：常见的后端消息队列**Kafka、RocketMQ**甚至Redis等等都可以做缓冲层，第一层业务处理直接校验后丢到消息队列中，在洪峰过去后慢慢消费消息队列中的消息，执行具体的业务。另外执行过程中的耗时和耗计算资源的操作，也可以丢到消息队列或数据库中，等到谷时处理。
- **捋平毛刺**：有时候洪峰不一定来自外界，如果系统内部大量**定时任务**在同一时间执行，或与业务高峰期重合，很容易在监控中看到“毛刺”——短时间负载极高。一般解决方案就是错峰执行定时任务，或者分配到其他非核心业务系统中，把“毛刺”摊平。比如很多数据分析型任务都放在业务低谷期去执行，大量定时任务在创建时尽量加一些随机性来分散执行时间。
- **避免错误风暴带来的次生洪峰**：有时候网络抖动或短暂宕机，业务会出现各种异常或错误。这时处理不好很容易带来**次生灾害**，比如：很多代码都会做错误重试，不加控制的大量重试甚至会导致网络抖动恢复后的瞬间，积压的大量请求再次冲垮整个系统；还有一些代码没有做超时、降级等处理，可能导致大量的等待耗尽TCP连接，进而导致整个系统被冲垮。解决之道就是做限定次数、间隔指数级增长的Back-Off重试，设定超时、降级策略。



## 批量处理

**批量处理**同样可以看成“**时间换时间**”，其原理是**减少了重复的事情，是一种对执行流程的压缩**。以**个别批量操作更长的耗时为代价，在整体上换取了更多的时间**。



### 使用场景

- 打包合并的JS文件、雪碧图等等，将**一批资源**集中到一起，**一次性传输**；
- 前端动画使用requestAnimationFrame在UI渲染时**批量处理积压的变化**，而不是有变化立刻更新，在游戏开发中也有类似的应用；
- 前后端中使用**队列暂存临时产生的数据**，积压到一定数量再批量处理；
- 在不影响可扩展性情况下，**一个接口传输多种需要的数据**，减少大量ajax调用（**GraphQL**在这一点就做到了极致）；
- **系统间通信尽量发送整批数据**，比如**消息队列的发布订阅、存取缓存服务的数据、RPC调用、插入或更新数据库**等等，能批量做尽可能批量做，因为这些系统间通信的I/O时间开销已经很昂贵了；
- **数据积压到一定程度再落盘**，操作系统本身的写文件就是这么做的，Linux的fwrite只是写入缓冲区暂存，积压到一定程度再fsync刷盘。在应用层，很多高性能的数据库和K-V存储的实现都体现了这一点：一些NoSQL的LSM Tree的第一层就是在内存中先积压到一定大小再往下层合并；Redis的RDB结合AOF的落盘机制；Linux系统调用也提供了批量读写多个缓冲区文件的系统调用：readv/writev；
- **延迟地批量回收资源**，比如JVM的Survivor Space的S0和S1区互换、Redis的Key过期的清除策略。



### 分批数量

- 前端把所有文件打包成单个JS，大部分时候并不是最优解。Webpack提供了很多分块的机制，CSS和JS分开、JS按业务分更小的Chunk结合懒加载、一些体积大又不用在首屏用的第三方库设置external或单独分块，可能整体性能更高。不一定要一批搞定所有事情，分几个小批次反而用户体验的性能更好。
- Redis的**MGET、MSET**来批量存取数据时，每批大小**不宜过大**，因为Redis主线程只有一个，如果一批太大执行期间会让其他命令无法响应。经验上一批50-100个Key性能是不错的，但最好在真实环境下用真实大小的数据量化度量一下，做Benchmark测试才能确定一批大小的最优值。
- MySQL、Oracle这类RDBMS，最优的批量Insert的大小也视数据行的特性而定。我之前在2U8G的Oracle上用一些普遍的业务数据做过测试，批量插入时每批5000-10000条数据性能是最高的，每批过大会导致DML的解析耗时过长，甚至单个SQL语句体积超限，单批太多反而得不偿失。
- 消息队列的发布订阅，每批的消息长度尽量控制在1MB以内，有些云服务商提供的消息队列限制了最大长度，那这个长度可能就是**性能拐点**，比如AWS的SQS服务对单条消息的限制是256KB。



## 榨干系统资源

**让硬件资源都在处理真正有用的逻辑计算，而不是做无关的事情或空转**。从晶体管到集成电路、驱动程序、操作系统、直到高级编程语言的层层抽象，每一层抽象带来的**更强的通用性**、**更高的开发效率**，多是以**损失运行效率**为代价的。可以在用高级编程语言写代码的时候，在**保障可读性、可维护性基础上**用**运行效率更高、更适合运行时环境**的方式去写，**减少额外的性能损耗**。



### 聚焦

减少系统调用与上下文切换，让CPU聚焦。大部分互联网应用服务，耗时的部分不是计算，而是I/O。



### 蜕变

用更高效的数据结构、算法、第三方组件，让程序本身蜕变。

从逻辑短路、Map代替List遍历、减少锁范围，到应用FisherYates、Dijkstra这些经典算法，每一行代码细节，量变会发生质变。更何况某个算法就足以让系统性能产生一两个数量级的提升。



### 适应

因地制宜，适应特定的运行环境。

在浏览器中主要是优化方向是I/O、UI渲染引擎、JS执行引擎三个方面。I/O越少越好，能用WebSocket的地方就不用Ajax，能用Ajax的地方就不要刷整个页面；UI渲染方面，减少重排和重绘，比如Vue、React等MVVM框架的虚拟DOM用额外的计算换取最精简的DOM操作；JS执行引擎方面，少用动态性极高的写法，比如eval、随意修改对象或对象原型的属性。



## 水平扩容

本节的**水平扩容**以及下面一节的**分片**，可以算整体的性能提升而不是单点的性能优化，会因为引入额外组件**反而降低了处理单个请求的性能**。但当业务规模大到一定程度时，再好的单机硬件也无法承受流量的洪峰，就得水平扩容了，毕竟”众人拾柴火焰高”。

水平扩容必然引入负载均衡，水平扩容的前提是无状态。



## 分片

水平扩容针对无状态组件，分片针对有状态组件。二者原理都是提升并行度，但分片的难度更大。负载均衡也不再是简单的加权轮询了，而是进化成了各个分片的**协调器**。



## 无锁化

有些业务场景，比如库存业务，按照正常的逻辑去实现，水平扩容带来的提升非常有限，因为需要锁住库存，扣减，再解锁库存。票务系统也类似，为了避免超卖，需要有一把锁禁锢了横向扩展的能力。

不管是单机还是分布式微服务，锁都是制约并行度的一大因素。比如上篇提到的秒杀场景，库存就那么多，系统超卖了可能导致非常大的经济损失，但用分布式锁会导致即使服务扩容了成千上万个实例，最终无数请求仍然阻塞在分布式锁这个串行组件上了，再多水平扩展的实例也无用武之地。

避免竞争Race Condition 是最完美的解决办法。上篇说的应对秒杀场景，预取库存就是减轻竞态条件的例子，虽然取到服务器内存之后仍然有多线程的锁，但锁的粒度更细了，并发度也就提高了。



# Troubleshooting

复杂综合类型问题的定位思路：

![img](https://oss.xubighead.top/oss/image/202506/1930468801209536514.jpg)

# General Business

## 隐藏内部接口

### 业务场景

某些接口不支持外部访问，只能内网服务调用。



### 解决方案

#### 微服务隔离

将对外暴露的接口和对内暴露的接口分别放到两个微服务上，一个服务里所有的接口均对外暴露，另一个服务的接口只能内网服务间调用。

该方案需要额外编写一个只对内部暴露接口的微服务，将所有只能对内暴露的业务接口聚合到这个微服务里，通过这个聚合的微服务，分别去各个业务侧获取资源。

该方案，新增一个微服务做请求转发，增加了系统的复杂性，增大了调用耗时以及后期的维护成本。



####  网关 + redis 实现白名单机制

在 redis 里维护一套接口白名单列表，外部请求到达网关时，从 redis 获取接口白名单，在白名单内的接口放行，反之拒绝掉。

该方案的好处是，对业务代码零侵入，只需要维护好白名单列表即可。缺点在于白名单的维护是一个持续性投入的工作，另外，每次请求进来，都需要判断白名单，增加了系统响应耗时，考虑到正常情况下外部进来的请求大部分都是在白名单内的，只有极少数恶意请求才会被白名单机制所拦截，所以该方案的性价比很低。



#### 网关 + AOP

**对所有经过网关的请求的header里添加一个字段，业务侧接口收到请求后，判断header里是否有该字段，如果有，则说明该请求来自外部，没有，则属于内部服务的调用，再根据该接口是否属于内部接口来决定是否放行该请求。**

该方案将内外网访问权限的处理分布到各个业务侧进行，消除了由网关来处理的系统性瓶颈；同时，开发者可以在业务侧直接确定接口的内外网访问权限，提升开发效率的同时，增加了代码的可读性。

该方案会对业务代码有一定的侵入性，不过可以通过注解的形式，最大限度的降低这种侵入性。



- 网关侧对进来的请求header添加外网标识符: from=public

```java
@Component
public class PublicRequestFilter implements GlobalFilter, Ordered {
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        return chain.filter(
            exchange.mutate().request(
                exchange.getRequest().mutate().header("id", "").header("from", "public").build())
                .build()
        );
    }

    @Override
    public int getOrder() {
        return 0;
    }
}
```



- 编写内外网访问权限判断的AOP和注解

```java
@Aspect
@Component
@Slf4j
public class OnlyIntranetAccessAspect {
    @Pointcut("@within(com.demo.spring.aop.OnlyIntranetAccess)")
    public void onlyIntranetAccessOnClass() {
    }

    @Pointcut("@annotation(com.demo.spring.aop.OnlyIntranetAccess)")
    public void onlyIntranetAccessOnMethod() {
    }

    @Before(value = "onlyIntranetAccessOnMethod() || onlyIntranetAccessOnClass()")
    public void before() {
        HttpServletRequest hsr = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest();
        String from = hsr.getHeader("from");
        if (!StringUtils.isEmpty(from) && "public".equals(from)) {
            log.error("This api is only allowed invoked by intranet source");
            throw new ServiceException("This api is only allowed invoked by intranet source");
        }
    }
}
```



```java
@Target({ElementType.METHOD})
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface OnlyIntranetAccess {
}
```



- 最后在只能内网访问的接口上加上@OnlyIntranetAccess注解



## 接口幂等

### 概述

所谓接口幂等性，就是一次和多次请求某一个资源对于资源本身应该具有同样的结果。

在微服务的时代，服务化接口在外部调用者会存在多次调用的情况(考虑网络中断重试等)，为了防止外部多次调用对系统数据状态的发生多次改变，将服务设计成幂等，就是为了防止多次重试，造成系统不一致的问题。



#### 添加幂等性对系统的影响

- 把并行执行的功能改为串行执行，降低了执行效率
- 增加了额外控制幂等的业务逻辑，复杂化了业务功能



#### 防重和幂等的区别

防重主要为了避免产生重复数据，把重复请求拦截下来即可。而幂等设计除了拦截已经处理的请求，还要求每次**相同的请求都返回一样的效果**。不过呢，很多时候，它们的处理流程可以是类似的。



### 业务场景

**前端重复提交表单：**在填写一些表格时候，用户填写完成提交，很多时候会因网络波动没有及时对用户做出提交成功响应，致使用户认为没有成功提交，然后一直点提交按钮，这时就会发生重复提交表单请求。

**用户恶意进行刷单：**例如在实现用户投票这种功能时，如果用户针对一个用户进行重复提交投票，这样会导致接口接收到用户重复提交的投票信息，这样会使投票结果与事实严重不符。

**接口超时重复提交：**很多时候 HTTP 客户端工具都默认开启超时重试的机制，尤其是第三方调用接口时候，为了防止网络波动超时等造成的请求失败，都会添加重试机制，导致一个请求提交多次。

**消息进行重复消费：**当使用 MQ 消息中间件时候，如果发生消息中间件出现错误未及时提交消费信息，导致发生重复消费。



### 解决方案

#### 数据库唯一主键

数据库唯一主键的实现主要是利用数据库中主键唯一约束的特性，一般来说唯一主键比较适用于“插入”时的幂等性，其能保证一张表中只能存在一条带该唯一主键的记录。

使用数据库唯一主键完成幂等性时需要注意的是，该主键一般来说并不是使用数据库中自增主键，而是使用分布式 全局ID 充当主键，这样才能能保证在分布式环境下 ID 的全局唯一性。

适合插入和删除操作。



#### 数据库乐观锁

数据库乐观锁方案一般只能适用于执行“更新操作”的过程，可以提前在对应的数据表中多添加一个字段，充当当前数据的版本标识。

这样每次对该数据库该表的这条数据执行更新时，都会将该版本标识作为一个条件，值为上次待更新数据中的版本标识的值。

更新数据时首先和版本号作对比，如果不相等说明已经有其他的请求去更新数据了，提示更新失败。



#### 防重 Token 令牌

针对客户端连续点击或者调用方的超时重试等情况，例如提交订单，此种操作就可以用 Token 的机制实现防止重复提交。

简单的说就是调用方在调用接口的时候先向后端请求一个全局 ID（Token），请求的时候携带这个全局 ID 一起请求（Token 最好将其放到 Headers 中），后端需要对这个 Token 作为 Key，用户信息作为 Value 到 Redis 中进行键值内容校验，如果 Key 存在且 Value 匹配就执行删除命令，然后正常执行后面的业务逻辑。

如果不存在对应的 Key 或 Value 不匹配就返回重复执行的错误信息，这样来保证幂等操作。

![图片](https://oss.xubighead.top/oss/image/202506/1930468900459352066.jpg)

主要流程如上图：

- 服务端提供获取 Token 的接口，该 Token 可以是一个序列号，也可以是一个分布式 ID 或者 UUID 串。
- 客户端调用接口获取 Token，这时候服务端会生成一个 Token 串。
- 然后将该串存入 Redis 数据库中，以该 Token 作为 Redis 的键（注意设置过期时间）。
- 将 Token 返回到客户端，客户端拿到后应存到表单隐藏域中。
- 客户端在执行提交表单时，把 Token 存入到 Headers 中，执行业务请求带上该 Headers。
- 服务端接收到请求后从 Headers 中拿到 Token，然后根据 Token 到 Redis 中查找该 key 是否存在。
- 服务端根据 Redis 中是否存该 key 进行判断，如果存在就将该 key 删除，然后正常执行业务逻辑。如果不存在就抛异常，返回重复提交的错误信息。

注意，在并发情况下，执行 Redis 查找数据与删除需要保证原子性，否则很可能在并发下无法保证幂等性。其实现方法可以使用分布式锁或者使用 Lua 表达式来注销查询与删除操作。



#### 下游传递唯一序列号

所谓请求序列号，其实就是每次向服务端请求时候附带一个短时间内唯一不重复的序列号，该序列号可以是一个有序 ID，也可以是一个订单号，一般由下游生成，在调用上游服务端接口时附加该序列号和用于认证的 ID。

当上游服务器收到请求信息后拿取该 序列号 和下游 认证ID 进行组合，形成用于操作 Redis 的 Key，然后到 Redis 中查询是否存在对应的 Key 的键值对。

根据其结果：

- 如果存在，就说明已经对该下游的该序列号的请求进行了业务处理，这时可以直接响应重复请求的错误信息。
- 如果不存在，就以该 Key 作为 Redis 的键，以下游关键信息作为存储的值（例如下游商传递的一些业务逻辑信息），将该键值对存储到 Redis 中 ，然后再正常执行对应的业务逻辑即可。

![图片](https://oss.xubighead.top/oss/image/202506/1930468958609182722.jpg)

主要流程如上图：

- 下游服务生成分布式 ID 作为序列号，然后执行请求调用上游接口，并附带“唯一序列号”与请求的“认证凭据 ID”。
- 上游服务进行安全效验，检测下游传递的参数中是否存在“序列号”和“凭据 ID”。
- 上游服务到 Redis 中检测是否存在对应的“序列号”与“认证 ID”组成的 Key，如果存在就抛出重复执行的异常信息，然后响应下游对应的错误信息。如果不存在就以该“序列号”和“认证 ID”组合作为 Key，以下游关键信息作为 Value，进而存储到 Redis 中，然后正常执行接来来的业务逻辑。

上面步骤中插入数据到 Redis 一定要设置过期时间。这样能保证在这个时间范围内，如果重复调用接口，则能够进行判断识别。



# E-commerce Business

## 避免重复下单

### 描述

用户快速点了两次 “提交订单”  按钮，浏览器会向后端发送两条创建订单的请求，最终会创建两条一模一样的订单。



### 解决方案

解决方案就是采用**幂等机制**，多次请求和一次请求产生的效果是一样的。



#### 主键唯一约束

**对于下单流量不算高的系统，可以通过`请求唯一ID`+`数据表增加唯一索引约束`这种方案来实现防止接口重复提交。**

利用数据库自身特性 “主键唯一约束”，在插入订单记录时，带上主键值，如果订单重复，记录插入会失败。



操作过程：

![img](https://oss.xubighead.top/oss/image/202506/1930469009569976322.jpg)

- 当用户进入订单提交界面的时候，调用后端获取请求唯一ID，并将唯一ID值埋点在页面里面；
- 当用户点击提交按钮时，后端检查这个唯一ID是否用过，如果没有用过，继续后续逻辑；如果用过，就提示重复提交；
- 最关键的一步操作，就是把这个唯一ID 存入业务表中，同时设置这个字段为唯一索引类型，从数据库层面做防止重复提交。



之所以把获取`请求唯一ID`的生成规则放在后端，好处就是生成规则可以自己定义，也并不一定要用`uuid`来生成，也可以用雪花算法，或者自己设计一套计算规则，保证当前业务提交时请求ID是唯一的，比如事先生成唯一的订单号，作为请求唯一ID，然后再提交，规则放在后端来生成，会更加灵活！



#### Redis分布式锁

**整套方案完全基于`redis`来实现，同时结合`redis`的分布式锁来实现请求限流，之所以选择`redis`，是因为它是一个内存数据库，性能比关系型数据库强太多，即使每秒的下单请求量在几千，也能很好的应对，为关系型数据库起到降压作用**！



实现的逻辑，流程如下：

![img](https://oss.xubighead.top/oss/image/202506/1930469058928545793.jpg)

- 1.当用户进入订单提交界面的时候，调用后端获取请求唯一 ID，同时后端将请求唯一ID存储到`redis`中再返回给前端，前端将唯一 ID 值埋点在页面里面
- 2.当用户点击提交按钮时，后端检查这个请求唯一 ID 是否存在，如果不存在，提示错误信息；如果存在，继续后续检查流程
- 3.使用`redis`的分布式锁服务，对请求 ID 在限定的时间内进行加锁，如果加锁成功，继续后续流程；如果加锁失败，说明服务正在处理，请勿重复提交
- 4.最后一步，如果加锁成功后，需要将锁手动释放掉，以免再次请求时，提示同样的信息；同时如果任务执行成功，需要将`redis`中的请求唯一 ID 清理掉
- 5.至于数据库是否需要增加字段唯一索引，理论上可以不用加，如果加了更保险



#### 业务唯一标识

通过Redis分布式锁解决重复下单的方案时，每次提交的时候，需要先调用后端服务获取`请求唯一ID`，然后才能提交。这样的流程比较麻烦，可以**在服务端通过一些规则组合，生成本次请求唯一ID。**



实现的逻辑，流程如下：

![img](https://oss.xubighead.top/oss/image/202506/1930469111344762882.jpg)

- 1.用户点击提交按钮，服务端接受到请求后，通过规则计算出本次请求唯一ID值
- 2.使用`redis`的分布式锁服务，对请求 ID 在限定的时间内尝试进行加锁，如果加锁成功，继续后续流程；如果加锁失败，说明服务正在处理，请勿重复提交
- 3.最后一步，如果加锁成功后，需要将锁手动释放掉，以免再次请求时，提示同样的信息



将接口请求唯一 ID 的生成逻辑，放在服务端通过规则组合来实现，不需要前端提交接口的时候强制带上这个参数，在满足防止接口重复提交的要求同时，又能减少前端和测试提交接口的复杂度！



#### JS脚本控制

前端通过js脚本控制，无法解决用户刷新提交的请求。另外也无法解决恶意提交。不建议采用该方案，如果想用，也只是作为一个补充方案。



#### 附加参数校验

前后约定附加参数校验。当用户点击购买按钮时，渲染下单页面，展示商品、收货地址、运费、价格等信息，同时页面会埋上`Token `信息，用户提交订单时，后端业务逻辑会校验token，有且匹配才认为是合理请求。



## 订单快照，减少存储成本

商品信息是可以修改的，当用户下单后，为了更好解决后面可能存在的买卖纠纷，创建订单时会同步保存一份商品详情信息，称之为订单快照。

同一件商品，会有很多用户会购买，如果热销商品，短时间就会有上万的订单。如果每个订单都创建一份快照，存储成本太高。另外商品信息虽然支持修改，但毕竟是一个低频动作。我们可以理解成，大部分订单的商品快照信息都是一样的，除非下单时用户修改过。

如何实时识别修改动作是解决快照成本的关键所在。我们采用摘要比对的方法‍。创建订单时，先检查商品信息摘要是否已经存在，如果不存在，会创建快照记录。订单明细会关联商品的快照主键。



由于订单快照属于非核心操作，即使失败也不应该影响用户正常购买流程，所以通常采用异步流程执行。



## 购物车，混合存储

购物车是电商系统的标配功能，暂存用户想要购买的商品。分为添加商品、列表查看、结算下单三个动作。

服务端在用户登录态校验时，做了分支路由，当用户未登录时，会创建一个临时`Token`，作为用户的唯一标识，购物车数据挂载在该`Token`下，为了避免购物车数据相互影响以及设计的复杂度，这里会有一个临时购物车表。

临时购物车表的数据量并不会太大，用户不会一直闲着添加购物车玩，当用户登录后，查看自己的购物车，服务端会从请求的cookie里查找购物车`Token`标识，并查询临时购物车表是否有数据，然后合并到正式购物车表里。



## 库存超卖

### 描述

常见的库存扣减方式有：

- 下单减库存：即当买家下单后，在商品的总库存中减去买家购买数量。下单减库存是最简单的减库存方式，也是控制最精确的一种，下单时直接通过数据库的事务机制控制商品库存，这样一定不会出现超卖的情况。但是你要知道，有些人下完单可能并不会付款。
- 付款减库存：即买家下单后，并不立即减库存，而是等到有用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为可能商品已经被其他人买走了。
- 预扣库存：这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如 30 分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。

至于采用哪一种减库存方式更多是业务层面的考虑，减库存最核心的是大并发请求时保证数据库中的库存字段值不能为负数。



### 解决方案

#### 行级锁

通常在扣减库存的场景下使用行级锁，通过数据库引擎本身对记录加锁的控制，保证数据库的更新的安全性，并且通过`where`语句的条件，保证库存不会被减到 `0` 以下，也就是能够有效的控制超卖的场景。

```
update ... set amount = amount - 1 where id = $id and amount - 1 >=0
```



#### 无符号整数

设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时 SQL 语句会报错。



## MySQL读写分离带来的数据不一致问题

### 描述

互联网业务大部分都是 `读多写少`，为了提升数据库集群的吞吐性能，我们通常会采用 `主从架构`、`读写分离`。

部署一个主库实例，客户端请求`所有写操作`全部写到主库，然后借助 MySQL 自带的 `主从同步` 功能，做一些简单配置，可以近乎实时的将主库的数据同步给 `多个从库实例`，主从延迟非常小，一般**不超过 1 毫秒**。

主从同步虽然近乎实时，但还是有个 `时间差` ，主库数据刚更新完，但数据还没来得及同步到从库，后续`读请求`直接访问了从库，看到的还是旧数据，影响用户体验。



### 解决方案

支付成功后，并没有立即跳到 `订单详情页`，而是增加了一个 无关紧要的 `中间页（支付成功页）`，一是告诉你支付的结果是成功的，钱没丢，不要担心；另外也可以增加一些推荐商品，引流提升网站的GMV。最重要的，增加了一个缓冲期，为 `订单的主从库数据同步` 争取了更多的时间。



## 历史订单归档

### 描述

电商网站，一般只能查询3个月内的订单，如果你想看看3个月前的订单，需要访问历史订单页面。



### 解决方案

1、冷热数据区分的标准是什么？要结合业务思考，可能要找产品同学一块讨论才能做决策，切记不要拍脑袋。以电商订单为例：

- 方案一：以“下单时间”为标准，将3 个月前的订单数据当作冷数据，3 个月内的当作热数据。
- 方案二：根据“订单状态”字段来区分，已完结的订单当作冷数据，未完结的订单当作热数据。
- 方案三：组合方式，把下单时间 > 3 个月且状态为“已完结”的订单标识为冷数据，其他的当作热数据。

2、如何触发冷热数据的分离

- 方案一：直接修改业务代码，每次业务请求触发冷热数据判断，根据结果路由到对应的冷数据表或热数据表。缺点：如果判断标准是 `时间维度`，数据过期了无法主动感知。
- 方案二：如果觉得修改业务代码，耦合性高，不易于后期维护。可以通过监听数据库变更日志 binlog 方式来触发
- 方案三：常用的手段是跑定时任务，一般是选择凌晨系统压力小的时候，通过跑批任务，将满足条件的冷数据迁移到其他存储介质。在途业务表中只留下来少量的热点数据。

3、如何实现冷热数据分离，过程大概分为三步：

- 判断数据是冷、还是热
- 将冷数据插入冷数据表中
- 然后，从原来的热库中删除迁移的数据

4、如何使用冷热数据

- 方案一：界面设计时会有选项区分，如上面举例的电商订单
- 方案二：直接在业务代码里区分。


